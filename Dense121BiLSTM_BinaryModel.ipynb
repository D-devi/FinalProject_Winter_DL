{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8e94fa9820d24a389878a1755e76026c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0e12b91cea0448228ddd47103e2b9162",
              "IPY_MODEL_a94264cc3f0747a8ade7fdaab7357031",
              "IPY_MODEL_b7f4ffb7a9b841a0887591bf1e1f30dd"
            ],
            "layout": "IPY_MODEL_dd92de618ef243c8a410e5c8b3dd9cff"
          }
        },
        "0e12b91cea0448228ddd47103e2b9162": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd070a419b0543a3bbb8ec8fec3ab564",
            "placeholder": "​",
            "style": "IPY_MODEL_f1970d5eb57b4d6c8a40c3ac1bc0dc45",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "a94264cc3f0747a8ade7fdaab7357031": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4360d11d4e8a4ba9942b761e7301329b",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6d84bd8e34624e859c5ee7e7aa82f266",
            "value": 48
          }
        },
        "b7f4ffb7a9b841a0887591bf1e1f30dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbcc3ab7f26446faac99813352354bc3",
            "placeholder": "​",
            "style": "IPY_MODEL_70d0882435b64ca5b89603ad249f2eb7",
            "value": " 48.0/48.0 [00:00&lt;00:00, 5.69kB/s]"
          }
        },
        "dd92de618ef243c8a410e5c8b3dd9cff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd070a419b0543a3bbb8ec8fec3ab564": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1970d5eb57b4d6c8a40c3ac1bc0dc45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4360d11d4e8a4ba9942b761e7301329b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d84bd8e34624e859c5ee7e7aa82f266": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cbcc3ab7f26446faac99813352354bc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70d0882435b64ca5b89603ad249f2eb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "042c471c022a478b85430c4b88c481fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b3fdab931ff4cad9e98568ff359cfde",
              "IPY_MODEL_85b793772b214ad7b23e545b468365c1",
              "IPY_MODEL_514368d1ff12492b9b077a511df7bcff"
            ],
            "layout": "IPY_MODEL_3226c8c895de42da9eab059f20a33fdc"
          }
        },
        "6b3fdab931ff4cad9e98568ff359cfde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64458f2c07e040ea9d77378a8d711f5c",
            "placeholder": "​",
            "style": "IPY_MODEL_f63d0ffe39a0455ea00ff43c5e6c38f6",
            "value": "vocab.txt: 100%"
          }
        },
        "85b793772b214ad7b23e545b468365c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67953394f7ac4a4c81cc69ed13832c4c",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be571cb6e4e14bf8ae8aef13d81c6e89",
            "value": 231508
          }
        },
        "514368d1ff12492b9b077a511df7bcff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91207d5bcc024103b0245fcc36596398",
            "placeholder": "​",
            "style": "IPY_MODEL_1b6beeca983c46828117a4b7f3b6803f",
            "value": " 232k/232k [00:00&lt;00:00, 12.4MB/s]"
          }
        },
        "3226c8c895de42da9eab059f20a33fdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64458f2c07e040ea9d77378a8d711f5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f63d0ffe39a0455ea00ff43c5e6c38f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67953394f7ac4a4c81cc69ed13832c4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be571cb6e4e14bf8ae8aef13d81c6e89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "91207d5bcc024103b0245fcc36596398": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b6beeca983c46828117a4b7f3b6803f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4366ea811cdc426aac50bf819d4a7305": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_39c9d4af45b346d1bb63bc5fc7c2a88a",
              "IPY_MODEL_a7e9c52256cb4213a56549b677ba0c49",
              "IPY_MODEL_6716bd285d514662bc45a3aed8dcf404"
            ],
            "layout": "IPY_MODEL_0b1d024e751f4e65a3151c888fca4f09"
          }
        },
        "39c9d4af45b346d1bb63bc5fc7c2a88a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b5dff8673bb4afe98b8a672bbe5c622",
            "placeholder": "​",
            "style": "IPY_MODEL_04943779432047ec9dedc50f997fc50f",
            "value": "tokenizer.json: 100%"
          }
        },
        "a7e9c52256cb4213a56549b677ba0c49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22b21477ed0c4fbdb27a1c29ffa9c502",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b0dc7e368024f3197ea0de89cf709d6",
            "value": 466062
          }
        },
        "6716bd285d514662bc45a3aed8dcf404": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86d5f5df4c6d409ebcf900e99055d83b",
            "placeholder": "​",
            "style": "IPY_MODEL_9748d7772b0743b19764c7450f9bd7bb",
            "value": " 466k/466k [00:00&lt;00:00, 11.0MB/s]"
          }
        },
        "0b1d024e751f4e65a3151c888fca4f09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b5dff8673bb4afe98b8a672bbe5c622": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04943779432047ec9dedc50f997fc50f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22b21477ed0c4fbdb27a1c29ffa9c502": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b0dc7e368024f3197ea0de89cf709d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "86d5f5df4c6d409ebcf900e99055d83b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9748d7772b0743b19764c7450f9bd7bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a217c9b824124e7a8c4e0e8adf17c62b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ca5bdbf634da4428bddd08702abc6d1f",
              "IPY_MODEL_7f6bbdb70e20451cb95513de0c870aaa",
              "IPY_MODEL_59a5fb0fd71b4eaebc8dfadb7139d171"
            ],
            "layout": "IPY_MODEL_abe60ccff2044d5198123a2d252fe98f"
          }
        },
        "ca5bdbf634da4428bddd08702abc6d1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_786f369c7fc846169eef7baec57b4695",
            "placeholder": "​",
            "style": "IPY_MODEL_58117fe47deb4032a0a1cc32d80c20b8",
            "value": "config.json: 100%"
          }
        },
        "7f6bbdb70e20451cb95513de0c870aaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbf0e47164914a0e93278eeeb1274010",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3173694865a84b9b81db8a6b5788e77f",
            "value": 570
          }
        },
        "59a5fb0fd71b4eaebc8dfadb7139d171": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c344a1e345d4b5a8a5483e72e3e01ab",
            "placeholder": "​",
            "style": "IPY_MODEL_3f22b21e74b047d39edfc107055ec6f5",
            "value": " 570/570 [00:00&lt;00:00, 71.6kB/s]"
          }
        },
        "abe60ccff2044d5198123a2d252fe98f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "786f369c7fc846169eef7baec57b4695": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58117fe47deb4032a0a1cc32d80c20b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bbf0e47164914a0e93278eeeb1274010": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3173694865a84b9b81db8a6b5788e77f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8c344a1e345d4b5a8a5483e72e3e01ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f22b21e74b047d39edfc107055ec6f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing & Feature Extraction"
      ],
      "metadata": {
        "id": "KY2m69c4yDw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2paFosKtM4Di",
        "outputId": "60f812d8-ad69-4be7-9689-f8b913484554"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.5.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.5.1-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.4/491.4 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.1 dill-0.3.8 fsspec-2025.3.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from datasets import Dataset, DatasetDict\n",
        "import pandas as pd\n",
        "import os\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def set_seed(seed_value=42):\n",
        "    \"\"\"Set seed for reproducibility for PyTorch and NumPy.\n",
        "\n",
        "    Args:\n",
        "        seed_value (int): The seed value to set for random number generators.\n",
        "    \"\"\"\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "set_seed(42)\n"
      ],
      "metadata": {
        "id": "J8976Y8C4nJR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1602de34-31d5-4399-e95d-b4683e9c82f1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Project path\n",
        "path_project = '/content/drive/MyDrive/Project'\n",
        "\n",
        "# 2) Load + preprocess + split\n",
        "def vqa_rad_setup(path_project):\n",
        "    json_file = \"VQA_RAD Dataset Public.json\"\n",
        "    image_folder = \"VQA_RAD Image Folder\"\n",
        "    json_path = os.path.join(path_project, json_file)\n",
        "    image_dir  = os.path.join(path_project, image_folder)\n",
        "\n",
        "\n",
        "\n",
        "    df = pd.read_json(json_path)\n",
        "    # build full image paths\n",
        "    df['image_path'] = df['image_name'].apply(lambda fn: os.path.join(image_dir, fn))\n",
        "\n",
        "    total_rows     = len(df)\n",
        "    print(f\"Total rows in df_binary:      {total_rows}\")\n",
        "\n",
        "\n",
        "    num_organs = df['image_organ'].nunique()\n",
        "    print(f\"There are {num_organs} distinct organs.\")\n",
        "\n",
        "    # 3) if you want to see them all:\n",
        "    print(\"Organ list:\", df['image_organ'].unique())\n",
        "\n",
        "    # filter to yes/no and map to 0/1\n",
        "    df['answer'] = df['answer'].str.strip().str.lower()\n",
        "    df_binary = df[df['answer'].isin(['yes', 'no'])].copy()\n",
        "    df_binary['label'] = df_binary['answer'].map({'yes': 1, 'no': 0})\n",
        "\n",
        "    # shuffle, select columns, print\n",
        "    df_binary = (\n",
        "        df_binary[['image_path', 'question', 'label']]\n",
        "        .sample(frac=1, random_state=42)\n",
        "        .reset_index(drop=True)\n",
        "    )\n",
        "\n",
        "    total_rows     = len(df_binary)\n",
        "    print(f\"Total rows in df_binary:      {total_rows}\")\n",
        "    return df_binary\n"
      ],
      "metadata": {
        "id": "e8vUl9880sQI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_binary = vqa_rad_setup(path_project)\n",
        "\n",
        "df_binary.head(10)"
      ],
      "metadata": {
        "id": "vp1xyT2F29sh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "73afe26e-cdbb-4685-df62-35f28ee2ff2e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total rows in df_binary:      2248\n",
            "There are 3 distinct organs.\n",
            "Organ list: ['HEAD' 'CHEST' 'ABD']\n",
            "Total rows in df_binary:      1193\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          image_path  \\\n",
              "0  /content/drive/MyDrive/Project/VQA_RAD Image F...   \n",
              "1  /content/drive/MyDrive/Project/VQA_RAD Image F...   \n",
              "2  /content/drive/MyDrive/Project/VQA_RAD Image F...   \n",
              "3  /content/drive/MyDrive/Project/VQA_RAD Image F...   \n",
              "4  /content/drive/MyDrive/Project/VQA_RAD Image F...   \n",
              "5  /content/drive/MyDrive/Project/VQA_RAD Image F...   \n",
              "6  /content/drive/MyDrive/Project/VQA_RAD Image F...   \n",
              "7  /content/drive/MyDrive/Project/VQA_RAD Image F...   \n",
              "8  /content/drive/MyDrive/Project/VQA_RAD Image F...   \n",
              "9  /content/drive/MyDrive/Project/VQA_RAD Image F...   \n",
              "\n",
              "                                           question  label  \n",
              "0   Are the patients' ribs symmetric on both sides?      0  \n",
              "1  Are there cilia present at the level of alveoli?      0  \n",
              "2                            Is this coronal plane?      1  \n",
              "3                        Is the patient lying down?      1  \n",
              "4  Do you see a cavitary lesion in this chest xray?      1  \n",
              "5            Is there free air under the diaphragm?      0  \n",
              "6                      is there tracheal deviation?      0  \n",
              "7            Is this in the lumbar vertebral level?      1  \n",
              "8            Does this patient have a pneumothorax?      0  \n",
              "9               Was this patient given IV contrast?      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b9103015-7c48-40d6-bce9-cf4cb9fb8003\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_path</th>\n",
              "      <th>question</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/Project/VQA_RAD Image F...</td>\n",
              "      <td>Are the patients' ribs symmetric on both sides?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/Project/VQA_RAD Image F...</td>\n",
              "      <td>Are there cilia present at the level of alveoli?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/Project/VQA_RAD Image F...</td>\n",
              "      <td>Is this coronal plane?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/Project/VQA_RAD Image F...</td>\n",
              "      <td>Is the patient lying down?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/MyDrive/Project/VQA_RAD Image F...</td>\n",
              "      <td>Do you see a cavitary lesion in this chest xray?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>/content/drive/MyDrive/Project/VQA_RAD Image F...</td>\n",
              "      <td>Is there free air under the diaphragm?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>/content/drive/MyDrive/Project/VQA_RAD Image F...</td>\n",
              "      <td>is there tracheal deviation?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>/content/drive/MyDrive/Project/VQA_RAD Image F...</td>\n",
              "      <td>Is this in the lumbar vertebral level?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>/content/drive/MyDrive/Project/VQA_RAD Image F...</td>\n",
              "      <td>Does this patient have a pneumothorax?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>/content/drive/MyDrive/Project/VQA_RAD Image F...</td>\n",
              "      <td>Was this patient given IV contrast?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b9103015-7c48-40d6-bce9-cf4cb9fb8003')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b9103015-7c48-40d6-bce9-cf4cb9fb8003 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b9103015-7c48-40d6-bce9-cf4cb9fb8003');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-018ea1fd-383c-4dcc-add2-394138360331\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-018ea1fd-383c-4dcc-add2-394138360331')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-018ea1fd-383c-4dcc-add2-394138360331 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_binary",
              "summary": "{\n  \"name\": \"df_binary\",\n  \"rows\": 1193,\n  \"fields\": [\n    {\n      \"column\": \"image_path\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 294,\n        \"samples\": [\n          \"/content/drive/MyDrive/Project/VQA_RAD Image Folder/synpic34947.jpg\",\n          \"/content/drive/MyDrive/Project/VQA_RAD Image Folder/synpic31757.jpg\",\n          \"/content/drive/MyDrive/Project/VQA_RAD Image Folder/synpic53228.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1029,\n        \"samples\": [\n          \"Besides the mass in the temporal horn, are there other enhancements in the image?\",\n          \"Is this film taken in a PA modality?\",\n          \"Is this a MRI of the chest?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLRsVaozao09",
        "outputId": "b96151a8-b7ee-4ea3-b3f0-1131a6eed651"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n",
            "100%|██████████| 30.8M/30.8M [00:00<00:00, 225MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import CLIPProcessor, CLIPModel\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 3) Instantiate your MedCLIP processor\n",
        "##model_name = \"openai/clip-vit-base-patch32\"  # You can choose different CLIP model variants\n",
        "#processor = CLIPProcessor.from_pretrained(model_name)\n",
        "\n",
        "\n",
        "def densenet_processor():\n",
        "    return transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(\n",
        "            mean=[0.485, 0.456, 0.406],\n",
        "            std=[0.229, 0.224, 0.225]\n",
        "        )\n",
        "    ])\n",
        "\n",
        "def transform_image_pre(image_path):\n",
        "    image = Image.open(image_path)\n",
        "    if image.mode != 'RGB':\n",
        "        image = image.convert('RGB')\n",
        "    return densenet_processor()(image)\n",
        "\n",
        "\n",
        "# 6) Batch‑load all train images into one big tensor\n",
        "image_tensors = []\n",
        "failed_images = []\n",
        "\n",
        "for img_path in tqdm(df_binary['image_path'], desc=\"Processing images\"):\n",
        "    try:\n",
        "        tensor = transform_image_pre(img_path)\n",
        "        image_tensors.append(tensor)\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Skipped {img_path}: {e}\")\n",
        "        failed_images.append(img_path)\n",
        "\n",
        "full_image_tensor = torch.stack(image_tensors, dim=0)\n",
        "print(f\"\\nProcessed {len(image_tensors)} images; skipped {len(failed_images)}.\")\n",
        "print(\"full_image_tensor.shape =\", full_image_tensor.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7ZbtIxVttK2",
        "outputId": "0015f9b8-db02-4efb-9ba8-d7127b6655ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing images: 100%|██████████| 1193/1193 [00:12<00:00, 97.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processed 1193 images; skipped 0.\n",
            "full_image_tensor.shape = torch.Size([1193, 3, 224, 224])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.checkpoint as cp\n",
        "from collections import OrderedDict\n",
        "\n",
        "\n",
        "\n",
        "def _bn_function_factory(norm, relu, conv):\n",
        "    def bn_function(*inputs):\n",
        "        concated_features = torch.cat(inputs, 1)\n",
        "        bottleneck_output = conv(relu(norm(concated_features)))\n",
        "        return bottleneck_output\n",
        "\n",
        "    return bn_function\n",
        "\n",
        "\n",
        "class _DenseLayer(nn.Sequential):\n",
        "    def __init__(self, num_input_features, growth_rate, bn_size, drop_rate, memory_efficient=False):\n",
        "        super(_DenseLayer, self).__init__()\n",
        "        self.add_module('norm1', nn.BatchNorm2d(num_input_features)),\n",
        "        self.add_module('relu1', nn.ReLU(inplace=True)),\n",
        "        self.add_module('conv1', nn.Conv2d(num_input_features, bn_size *\n",
        "                                           growth_rate, kernel_size=1, stride=1,\n",
        "                                           bias=False)),\n",
        "        self.add_module('norm2', nn.BatchNorm2d(bn_size * growth_rate)),\n",
        "        self.add_module('relu2', nn.ReLU(inplace=True)),\n",
        "        self.add_module('conv2', nn.Conv2d(bn_size * growth_rate, growth_rate,\n",
        "                                           kernel_size=3, stride=1, padding=1,\n",
        "                                           bias=False)),\n",
        "        self.drop_rate = drop_rate\n",
        "        self.memory_efficient = memory_efficient\n",
        "\n",
        "    def forward(self, *prev_features):\n",
        "        bn_function = _bn_function_factory(self.norm1, self.relu1, self.conv1)\n",
        "        if self.memory_efficient and any(prev_feature.requires_grad for prev_feature in prev_features):\n",
        "            bottleneck_output = cp.checkpoint(bn_function, *prev_features)\n",
        "        else:\n",
        "            bottleneck_output = bn_function(*prev_features)\n",
        "        new_features = self.conv2(self.relu2(self.norm2(bottleneck_output)))\n",
        "        if self.drop_rate > 0:\n",
        "            new_features = F.dropout(new_features, p=self.drop_rate,\n",
        "                                     training=self.training)\n",
        "        return new_features\n",
        "\n",
        "\n",
        "class _DenseBlock(nn.Module):\n",
        "    def __init__(self, num_layers, num_input_features, bn_size, growth_rate, drop_rate, memory_efficient=False):\n",
        "        super(_DenseBlock, self).__init__()\n",
        "        for i in range(num_layers):\n",
        "            layer = _DenseLayer(\n",
        "                num_input_features + i * growth_rate,\n",
        "                growth_rate=growth_rate,\n",
        "                bn_size=bn_size,\n",
        "                drop_rate=drop_rate,\n",
        "                memory_efficient=memory_efficient,\n",
        "            )\n",
        "            self.add_module('denselayer%d' % (i + 1), layer)\n",
        "\n",
        "    def forward(self, init_features):\n",
        "        features = [init_features]\n",
        "        for name, layer in self.named_children():\n",
        "            new_features = layer(*features)\n",
        "            features.append(new_features)\n",
        "        return torch.cat(features, 1)\n",
        "\n",
        "\n",
        "class _Transition(nn.Sequential):\n",
        "    def __init__(self, num_input_features, num_output_features):\n",
        "        super(_Transition, self).__init__()\n",
        "        self.add_module('norm', nn.BatchNorm2d(num_input_features))\n",
        "        self.add_module('relu', nn.ReLU(inplace=True))\n",
        "        self.add_module('conv', nn.Conv2d(num_input_features, num_output_features,\n",
        "                                          kernel_size=1, stride=1, bias=False))\n",
        "        self.add_module('pool', nn.AvgPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "\n",
        "class DenseNet121(nn.Module):\n",
        "    r\"\"\"Densenet-BC model class, based on\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        growth_rate (int) - how many filters to add each layer (`k` in paper)\n",
        "        block_config (list of 4 ints) - how many layers in each pooling block\n",
        "        num_init_featuremaps (int) - the number of filters to learn in the first convolution layer\n",
        "        bn_size (int) - multiplicative factor for number of bottle neck layers\n",
        "          (i.e. bn_size * k features in the bottleneck layer)\n",
        "        drop_rate (float) - dropout rate after each dense layer\n",
        "        num_classes (int) - number of classification classes\n",
        "        memory_efficient (bool) - If True, uses checkpointing. Much more memory efficient,\n",
        "          but slower. Default: *False*. See `\"paper\" <https://arxiv.org/pdf/1707.06990.pdf>`_\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, growth_rate=32, block_config=(6, 12, 24, 16),\n",
        "                 num_init_featuremaps=64, bn_size=4, drop_rate=0, num_classes=1000, memory_efficient=False,\n",
        "                 grayscale=False):\n",
        "\n",
        "        super(DenseNet121, self).__init__()\n",
        "\n",
        "        # First convolution\n",
        "        if grayscale:\n",
        "            in_channels=1\n",
        "        else:\n",
        "            in_channels=3\n",
        "\n",
        "        self.features = nn.Sequential(OrderedDict([\n",
        "            ('conv0', nn.Conv2d(in_channels=in_channels, out_channels=num_init_featuremaps,\n",
        "                                kernel_size=7, stride=2,\n",
        "                                padding=3, bias=False)), # bias is redundant when using batchnorm\n",
        "            ('norm0', nn.BatchNorm2d(num_features=num_init_featuremaps)),\n",
        "            ('relu0', nn.ReLU(inplace=True)),\n",
        "            ('pool0', nn.MaxPool2d(kernel_size=3, stride=2, padding=1)),\n",
        "        ]))\n",
        "\n",
        "        # Each denseblock\n",
        "        num_features = num_init_featuremaps\n",
        "        for i, num_layers in enumerate(block_config):\n",
        "            block = _DenseBlock(\n",
        "                num_layers=num_layers,\n",
        "                num_input_features=num_features,\n",
        "                bn_size=bn_size,\n",
        "                growth_rate=growth_rate,\n",
        "                drop_rate=drop_rate,\n",
        "                memory_efficient=memory_efficient\n",
        "            )\n",
        "            self.features.add_module('denseblock%d' % (i + 1), block)\n",
        "            num_features = num_features + num_layers * growth_rate\n",
        "            if i != len(block_config) - 1:\n",
        "                trans = _Transition(num_input_features=num_features,\n",
        "                                    num_output_features=num_features // 2)\n",
        "                self.features.add_module('transition%d' % (i + 1), trans)\n",
        "                num_features = num_features // 2\n",
        "\n",
        "        # Final batch norm\n",
        "        self.features.add_module('norm5', nn.BatchNorm2d(num_features))\n",
        "\n",
        "        # Linear layer\n",
        "        self.classifier = nn.Linear(num_features, num_classes)\n",
        "\n",
        "        # Official init from torch repo.\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.features(x)\n",
        "        out = F.relu(features, inplace=True)\n",
        "        out = F.adaptive_avg_pool2d(out, (1, 1))\n",
        "        out = torch.flatten(out, 1)\n",
        "        logits = self.classifier(out)\n",
        "        probas = F.softmax(logits, dim=1)\n",
        "        return logits, probas"
      ],
      "metadata": {
        "id": "Hx05lXdugH5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "vocab_size = tokenizer.vocab_size\n",
        "print(f\"Loaded BERT tokenizer with vocab size: {vocab_size}\")\n",
        "\n",
        "\n",
        "# Set max sequence length for tokenization\n",
        "max_seq_length = 64  # or any other value appropriate for your dataset\n",
        "\n",
        "# Tokenize all questions\n",
        "all_tokenized_texts = []\n",
        "for description in df_binary['question']:\n",
        "    tokenized_text = tokenizer(\n",
        "        description,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        max_length=max_seq_length,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    all_tokenized_texts.append(tokenized_text)\n",
        "\n",
        "print(f\"\\nTokenized {len(all_tokenized_texts)} questions.\")\n",
        "\n",
        "# Stack all input_ids and attention_mask tensors\n",
        "Text_tensor = torch.cat([item['input_ids'] for item in all_tokenized_texts], dim=0)  # [N, max_seq_length]\n",
        "Text_attention_mask_tensor = torch.cat([item['attention_mask'] for item in all_tokenized_texts], dim=0)\n",
        "\n",
        "# Final checks\n",
        "print(f\"\\n✅ Shape of Text_tensor: {Text_tensor.shape}\")                             # [N, max_seq_length]\n",
        "print(f\"✅ Shape of Attention Mask Tensor: {Text_attention_mask_tensor.shape}\")       # [N, max_seq_length]\n",
        "print(f\"ℹ️  Max token ID: {Text_tensor.max().item()} < Vocab Size: {vocab_size}? {'Yes ✅' if Text_tensor.max().item() < vocab_size else 'No ❌'}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386,
          "referenced_widgets": [
            "8e94fa9820d24a389878a1755e76026c",
            "0e12b91cea0448228ddd47103e2b9162",
            "a94264cc3f0747a8ade7fdaab7357031",
            "b7f4ffb7a9b841a0887591bf1e1f30dd",
            "dd92de618ef243c8a410e5c8b3dd9cff",
            "fd070a419b0543a3bbb8ec8fec3ab564",
            "f1970d5eb57b4d6c8a40c3ac1bc0dc45",
            "4360d11d4e8a4ba9942b761e7301329b",
            "6d84bd8e34624e859c5ee7e7aa82f266",
            "cbcc3ab7f26446faac99813352354bc3",
            "70d0882435b64ca5b89603ad249f2eb7",
            "042c471c022a478b85430c4b88c481fa",
            "6b3fdab931ff4cad9e98568ff359cfde",
            "85b793772b214ad7b23e545b468365c1",
            "514368d1ff12492b9b077a511df7bcff",
            "3226c8c895de42da9eab059f20a33fdc",
            "64458f2c07e040ea9d77378a8d711f5c",
            "f63d0ffe39a0455ea00ff43c5e6c38f6",
            "67953394f7ac4a4c81cc69ed13832c4c",
            "be571cb6e4e14bf8ae8aef13d81c6e89",
            "91207d5bcc024103b0245fcc36596398",
            "1b6beeca983c46828117a4b7f3b6803f",
            "4366ea811cdc426aac50bf819d4a7305",
            "39c9d4af45b346d1bb63bc5fc7c2a88a",
            "a7e9c52256cb4213a56549b677ba0c49",
            "6716bd285d514662bc45a3aed8dcf404",
            "0b1d024e751f4e65a3151c888fca4f09",
            "7b5dff8673bb4afe98b8a672bbe5c622",
            "04943779432047ec9dedc50f997fc50f",
            "22b21477ed0c4fbdb27a1c29ffa9c502",
            "1b0dc7e368024f3197ea0de89cf709d6",
            "86d5f5df4c6d409ebcf900e99055d83b",
            "9748d7772b0743b19764c7450f9bd7bb",
            "a217c9b824124e7a8c4e0e8adf17c62b",
            "ca5bdbf634da4428bddd08702abc6d1f",
            "7f6bbdb70e20451cb95513de0c870aaa",
            "59a5fb0fd71b4eaebc8dfadb7139d171",
            "abe60ccff2044d5198123a2d252fe98f",
            "786f369c7fc846169eef7baec57b4695",
            "58117fe47deb4032a0a1cc32d80c20b8",
            "bbf0e47164914a0e93278eeeb1274010",
            "3173694865a84b9b81db8a6b5788e77f",
            "8c344a1e345d4b5a8a5483e72e3e01ab",
            "3f22b21e74b047d39edfc107055ec6f5"
          ]
        },
        "id": "U-ioBP1Liy3k",
        "outputId": "359c58d8-7bcd-4868-a137-dcdbfe81d54a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e94fa9820d24a389878a1755e76026c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "042c471c022a478b85430c4b88c481fa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4366ea811cdc426aac50bf819d4a7305"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a217c9b824124e7a8c4e0e8adf17c62b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded BERT tokenizer with vocab size: 30522\n",
            "\n",
            "Tokenized 1193 questions.\n",
            "\n",
            "✅ Shape of Text_tensor: torch.Size([1193, 64])\n",
            "✅ Shape of Attention Mask Tensor: torch.Size([1193, 64])\n",
            "ℹ️  Max token ID: 29561 < Vocab Size: 30522? Yes ✅\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we use torch for modeling neural networks including CNNs\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "D8tOABY15U5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2zQksNtcR5zg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class BiLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, num_layers, dropout):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=emb_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=True,\n",
        "            dropout=dropout if num_layers > 1 else 0.0\n",
        "        )\n",
        "        # project bidirectional hidden to single vector\n",
        "        self.fc = nn.Linear(hidden_dim * 2, hidden_dim)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        # input_ids: [B, T], attention_mask: [B, T]\n",
        "        embeds = self.embedding(input_ids)                      # [B, T, emb_dim]\n",
        "        lengths = attention_mask.sum(dim=1).cpu()               # actual lengths\n",
        "        packed = nn.utils.rnn.pack_padded_sequence(\n",
        "            embeds, lengths, batch_first=True, enforce_sorted=False\n",
        "        )\n",
        "        packed_out, (h_n, _) = self.lstm(packed)\n",
        "        # h_n: [num_layers*2, B, hidden_dim]\n",
        "        # take last forward & backward layers\n",
        "        h_fwd = h_n[-2]                                         # [B, hidden_dim]\n",
        "        h_bwd = h_n[-1]                                         # [B, hidden_dim]\n",
        "        h_cat = torch.cat([h_fwd, h_bwd], dim=1)                # [B, hidden_dim*2]\n",
        "        out = self.fc(h_cat)                                    # [B, hidden_dim]\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "OszrBE9OdHw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader"
      ],
      "metadata": {
        "id": "SSyOViWRlJ8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_train_tensor = torch.tensor(df_binary['label'], dtype=torch.float32)\n",
        "\n",
        "# 1) Instantiate your BiLSTM text encoder\n",
        "hidden_dim = 256\n",
        "text_model = BiLSTM(\n",
        "    vocab_size=vocab_size,\n",
        "    emb_dim=256,\n",
        "    hidden_dim=hidden_dim,\n",
        "    num_layers=2,\n",
        "    dropout=0.2\n",
        ").to(device).eval()\n",
        "\n",
        "# 2) Load DenseNet121 as image feature extractor\n",
        "from torchvision import models\n",
        "densenet = models.densenet121(pretrained=True).to(device).eval()\n",
        "feature_extractor = nn.Sequential(\n",
        "    densenet.features,\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.AdaptiveAvgPool2d((1, 1)),\n",
        "    nn.Flatten(start_dim=1)\n",
        ").to(device).eval()\n",
        "\n",
        "# 3) Feature extraction function\n",
        "def data_all_features(image_data, text_data, text_attention):\n",
        "    image_features = []\n",
        "    text_features = []\n",
        "\n",
        "    for img, input_ids, attention_mask in tqdm(zip(image_data, text_data, text_attention), total=len(image_data)):\n",
        "        img = img.unsqueeze(0).to(device)\n",
        "        input_ids = input_ids.unsqueeze(0).to(device)\n",
        "        attention_mask = attention_mask.unsqueeze(0).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # Image: [1, 3, 224, 224] → [1, 1024]\n",
        "            img_feat = feature_extractor(img)\n",
        "\n",
        "            # Text: [1, seq_len] → [1, hidden_dim]\n",
        "            txt_feat = text_model(input_ids, attention_mask)\n",
        "\n",
        "        image_features.append(img_feat.squeeze(0))\n",
        "        text_features.append(txt_feat.squeeze(0))\n",
        "\n",
        "    return torch.stack(image_features), torch.stack(text_features)\n",
        "\n",
        "# 4) Run feature extraction\n",
        "image_features, text_features = data_all_features(\n",
        "    full_image_tensor, Text_tensor, Text_attention_mask_tensor\n",
        ")\n",
        "\n",
        "# 5) Check shapes\n",
        "print(f\"✅ image_features shape: {image_features.shape}\")  # [N, 1024]\n",
        "print(f\"✅ text_features shape: {text_features.shape}\")    # [N, 256]\n",
        "\n",
        "N = 75\n",
        "\n",
        "Image_train = image_features[N:]\n",
        "Image_test = image_features[:N]\n",
        "Text_train = text_features[N:]\n",
        "Text_test = text_features[:N]\n",
        "y_train = y_train_tensor[N:]\n",
        "y_test = y_train_tensor[:N]\n",
        "\n",
        "## Dataloader with (image, text, labels)\n",
        "batch_size = 64\n",
        "train_dataset = TensorDataset(Image_train,Text_train, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_dataset = TensorDataset(Image_test,Text_test, y_test)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ArX9twS4PFB",
        "outputId": "e539ea61-99fb-4abe-dcd3-26f37cd1c523"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n",
            "100%|██████████| 30.8M/30.8M [00:00<00:00, 134MB/s]\n",
            "100%|██████████| 1193/1193 [00:26<00:00, 45.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ image_features shape: torch.Size([1193, 1024])\n",
            "✅ text_features shape: torch.Size([1193, 256])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_loader.dataset.tensors[0].shape)\n",
        "print(train_loader.dataset.tensors[1].shape)\n",
        "print(train_loader.dataset.tensors[2].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiJqgy32bxRG",
        "outputId": "b36c72f8-e0ae-4933-ad95-ffd92c8e23e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1118, 1024])\n",
            "torch.Size([1118, 256])\n",
            "torch.Size([1118])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class CoAttentionFusionClassifier(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        image_dim: int,\n",
        "        text_dim: int,\n",
        "        fusion_dim: int = 512,\n",
        "        num_heads: int = 8,\n",
        "        dropout: float = 0.1,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        # project each modality into the same hidden space\n",
        "        self.img_proj = nn.Linear(image_dim, fusion_dim)\n",
        "        self.txt_proj = nn.Linear(text_dim, fusion_dim)\n",
        "\n",
        "        # cross‑attention layers\n",
        "        # image queries, text keys/values\n",
        "        self.attn_img2txt = nn.MultiheadAttention(\n",
        "            embed_dim=fusion_dim, num_heads=num_heads, dropout=dropout, batch_first=True\n",
        "        )\n",
        "        # text queries, image keys/values\n",
        "        self.attn_txt2img = nn.MultiheadAttention(\n",
        "            embed_dim=fusion_dim, num_heads=num_heads, dropout=dropout, batch_first=True\n",
        "        )\n",
        "\n",
        "        # classification head\n",
        "        self.dropout    = nn.Dropout(dropout)\n",
        "        self.classifier = nn.Linear(fusion_dim, 1)\n",
        "\n",
        "    def forward(self, img_feat: torch.Tensor, txt_feat: torch.Tensor):\n",
        "        \"\"\"\n",
        "        img_feat: (B, image_dim)\n",
        "        txt_feat: (B, text_dim)\n",
        "        \"\"\"\n",
        "        # 1) project and add sequence dim → (B, 1, fusion_dim)\n",
        "        img = self.img_proj(img_feat).unsqueeze(1)\n",
        "        txt = self.txt_proj(txt_feat).unsqueeze(1)\n",
        "\n",
        "        # 2) co‑attention\n",
        "        # img attends to text:\n",
        "        img2txt, _ = self.attn_img2txt(query=img, key=txt, value=txt)\n",
        "        # text attends to image:\n",
        "        txt2img, _ = self.attn_txt2img(query=txt, key=img, value=img)\n",
        "\n",
        "        # 3) fuse by averaging both attended outputs and pooling the sequence dim\n",
        "        # each is (B,1,fusion_dim) → stack → (B,2,fusion_dim)\n",
        "        fused_seq = torch.cat([img2txt, txt2img], dim=1)\n",
        "        fused     = fused_seq.mean(dim=1)    # (B, fusion_dim)\n",
        "\n",
        "        # 4) classification\n",
        "        x      = self.dropout(fused)\n",
        "        logit  = self.classifier(x).squeeze(1)  # (B,)\n",
        "        return logit\n"
      ],
      "metadata": {
        "id": "q0ih8NI_ggBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "image_dim = image_features.shape[1]\n",
        "text_dim  = text_features.shape[1]\n",
        "\n"
      ],
      "metadata": {
        "id": "PK-TP5fxglxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "rs = [1e-3, 1e-4, 1e-5]\n",
        "dropouts = [0.1, 0.2, 0.3]\n",
        "n_epochs = 50 # fewer epochs for quick tuning\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 2) helper to train & eval one config\n",
        "def run_trial(lr, dropout, img2txt_mult, txt2img_mult):\n",
        "    # re‑init model\n",
        "    model = CoAttentionFusionClassifier(\n",
        "        image_dim=image_dim,\n",
        "        text_dim=text_dim,\n",
        "        fusion_dim=512,\n",
        "        num_heads=64,\n",
        "        dropout=dropout\n",
        "    ).to(device)\n",
        "\n",
        "    # 2) Define Parameter Groups (this is where you change the LR multipliers):\n",
        "    param_groups = [\n",
        "        {'params': [p for n, p in model.named_parameters() if 'attn_img2txt' in n], 'lr': lr * img2txt_mult}, # Fixed multiplier\n",
        "        {'params': [p for n, p in model.named_parameters() if 'attn_txt2img' in n], 'lr': lr * txt2img_mult}, # Fixed multiplier\n",
        "        {'params': [p for n, p in model.named_parameters() if 'attn' not in n]}, # Default LR for other params\n",
        "    ]\n",
        "\n",
        "    # 3) Initialize Optimizer with Parameter Groups:\n",
        "    opt = optim.Adam(param_groups, lr=lr)\n",
        "    crit = nn.BCEWithLogitsLoss()\n",
        "    best_f1 = 0.0\n",
        "    best_acc = 0.0\n",
        "    best_auroc = 0.0\n",
        "\n",
        "    for epoch in range(1, n_epochs+1):\n",
        "        # train one epoch\n",
        "        model.train()\n",
        "        for imgs, txts, labs in train_loader:\n",
        "            imgs, txts = imgs.to(device), txts.to(device)\n",
        "            labs = labs.to(device).float()\n",
        "            opt.zero_grad()\n",
        "            logits = model(imgs, txts)\n",
        "            loss = crit(logits, labs)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "        # eval\n",
        "        model.eval()\n",
        "        all_p, all_l = [], []\n",
        "        with torch.no_grad():\n",
        "            for imgs, txts, labs in test_loader:\n",
        "                imgs, txts = imgs.to(device), txts.to(device)\n",
        "                logits = model(imgs, txts)\n",
        "                preds = (torch.sigmoid(logits) > 0.5).long()\n",
        "                all_p.extend(preds.cpu().tolist())\n",
        "                all_l.extend(labs.tolist())\n",
        "\n",
        "        f1 = f1_score(all_l, all_p)\n",
        "        acc = accuracy_score(all_l, all_p)\n",
        "        auroc = roc_auc_score(all_l, all_p)\n",
        "        best_f1 = max(best_f1, f1)\n",
        "        best_acc = max(best_acc, acc)\n",
        "        best_auroc = max(best_auroc, auroc)\n",
        "\n",
        "    return best_f1, best_acc, best_auroc\n",
        "\n",
        "# 3) grid‐search\n",
        "# You also need to define img2txt_mults and txt2img_mults\n",
        "img2txt_mults = [0.5, 1.0, 2.0, 3.0]\n",
        "txt2img_mults = [0.5, 1.0, 2.0, 5.0]\n",
        "\n",
        "results = []\n",
        "for lr, dp, img2txt_mult, txt2img_mult in product(lrs, dropouts, img2txt_mults, txt2img_mults):\n",
        "    f1, acc, auroc = run_trial(lr, dp, img2txt_mult, txt2img_mult)  # Get all metrics\n",
        "    print(f\" → lr={lr:.0e}, dropout={dp:.1f}, img2txt_mult={img2txt_mult}, txt2img_mult={txt2img_mult} → best Val F1 = {f1:.4f}, best Val Acc = {acc:.4f}, best Val AUROC = {auroc:.4f}\\n\")\n",
        "    results.append((f1, acc, auroc, lr, dp, img2txt_mult, txt2img_mult))  # Store all metrics\n",
        "\n",
        "# 4) pick best\n",
        "best_result = max(results, key=lambda x: x[0])  # Find best by F1 score\n",
        "best_f1, best_acc, best_auroc, best_lr, best_dp, best_img2txt_mult, best_txt2img_mult = best_result\n",
        "\n",
        "# Print Best Configuration with LR Multipliers and AUROC:\n",
        "print(f\">>> Best config by F1: lr={best_lr:.0e}, dropout={best_dp:.1f}, img2txt_mult={best_img2txt_mult}, txt2img_mult={best_txt2img_mult} with Val F1={best_f1:.4f} (Acc={best_acc:.4f}, AUROC={best_auroc:.4f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIuS26uBqfEJ",
        "outputId": "5cf62fa9-6854-411a-d1f3-151292666d12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " → lr=1e-03, dropout=0.1, img2txt_mult=0.5, txt2img_mult=0.5 → best Val F1 = 0.7073, best Val Acc = 0.6800, best Val AUROC = 0.6848\n",
            "\n",
            " → lr=1e-03, dropout=0.1, img2txt_mult=0.5, txt2img_mult=1.0 → best Val F1 = 0.7059, best Val Acc = 0.6800, best Val AUROC = 0.6795\n",
            "\n",
            " → lr=1e-03, dropout=0.1, img2txt_mult=0.5, txt2img_mult=2.0 → best Val F1 = 0.7473, best Val Acc = 0.6933, best Val AUROC = 0.7030\n",
            "\n",
            " → lr=1e-03, dropout=0.1, img2txt_mult=0.5, txt2img_mult=5.0 → best Val F1 = 0.7253, best Val Acc = 0.7067, best Val AUROC = 0.7073\n",
            "\n",
            " → lr=1e-03, dropout=0.1, img2txt_mult=1.0, txt2img_mult=0.5 → best Val F1 = 0.7273, best Val Acc = 0.7067, best Val AUROC = 0.7073\n",
            "\n",
            " → lr=1e-03, dropout=0.1, img2txt_mult=1.0, txt2img_mult=1.0 → best Val F1 = 0.7294, best Val Acc = 0.6933, best Val AUROC = 0.6998\n",
            "\n",
            " → lr=1e-03, dropout=0.1, img2txt_mult=1.0, txt2img_mult=2.0 → best Val F1 = 0.7111, best Val Acc = 0.6800, best Val AUROC = 0.6795\n",
            "\n",
            " → lr=1e-03, dropout=0.1, img2txt_mult=1.0, txt2img_mult=5.0 → best Val F1 = 0.7229, best Val Acc = 0.6933, best Val AUROC = 0.6987\n",
            "\n",
            " → lr=1e-03, dropout=0.1, img2txt_mult=2.0, txt2img_mult=0.5 → best Val F1 = 0.7174, best Val Acc = 0.6933, best Val AUROC = 0.6944\n",
            "\n",
            " → lr=1e-03, dropout=0.1, img2txt_mult=2.0, txt2img_mult=1.0 → best Val F1 = 0.7143, best Val Acc = 0.6800, best Val AUROC = 0.6859\n",
            "\n",
            " → lr=1e-03, dropout=0.1, img2txt_mult=2.0, txt2img_mult=2.0 → best Val F1 = 0.7191, best Val Acc = 0.6800, best Val AUROC = 0.6848\n",
            "\n",
            " → lr=1e-03, dropout=0.1, img2txt_mult=2.0, txt2img_mult=5.0 → best Val F1 = 0.7368, best Val Acc = 0.7333, best Val AUROC = 0.7350\n",
            "\n",
            " → lr=1e-03, dropout=0.1, img2txt_mult=3.0, txt2img_mult=0.5 → best Val F1 = 0.7391, best Val Acc = 0.7067, best Val AUROC = 0.7073\n",
            "\n",
            " → lr=1e-03, dropout=0.1, img2txt_mult=3.0, txt2img_mult=1.0 → best Val F1 = 0.7191, best Val Acc = 0.6800, best Val AUROC = 0.6806\n",
            "\n",
            " → lr=1e-03, dropout=0.1, img2txt_mult=3.0, txt2img_mult=2.0 → best Val F1 = 0.7470, best Val Acc = 0.7200, best Val AUROC = 0.7254\n",
            "\n",
            " → lr=1e-03, dropout=0.1, img2txt_mult=3.0, txt2img_mult=5.0 → best Val F1 = 0.7333, best Val Acc = 0.6933, best Val AUROC = 0.6944\n",
            "\n",
            " → lr=1e-03, dropout=0.2, img2txt_mult=0.5, txt2img_mult=0.5 → best Val F1 = 0.7097, best Val Acc = 0.6800, best Val AUROC = 0.6827\n",
            "\n",
            " → lr=1e-03, dropout=0.2, img2txt_mult=0.5, txt2img_mult=1.0 → best Val F1 = 0.7234, best Val Acc = 0.6800, best Val AUROC = 0.6848\n",
            "\n",
            " → lr=1e-03, dropout=0.2, img2txt_mult=0.5, txt2img_mult=2.0 → best Val F1 = 0.7021, best Val Acc = 0.6933, best Val AUROC = 0.6944\n",
            "\n",
            " → lr=1e-03, dropout=0.2, img2txt_mult=0.5, txt2img_mult=5.0 → best Val F1 = 0.7073, best Val Acc = 0.6800, best Val AUROC = 0.6848\n",
            "\n",
            " → lr=1e-03, dropout=0.2, img2txt_mult=1.0, txt2img_mult=0.5 → best Val F1 = 0.7191, best Val Acc = 0.6800, best Val AUROC = 0.6838\n",
            "\n",
            " → lr=1e-03, dropout=0.2, img2txt_mult=1.0, txt2img_mult=1.0 → best Val F1 = 0.7191, best Val Acc = 0.7067, best Val AUROC = 0.7094\n",
            "\n",
            " → lr=1e-03, dropout=0.2, img2txt_mult=1.0, txt2img_mult=2.0 → best Val F1 = 0.6988, best Val Acc = 0.6800, best Val AUROC = 0.6827\n",
            "\n",
            " → lr=1e-03, dropout=0.2, img2txt_mult=1.0, txt2img_mult=5.0 → best Val F1 = 0.7416, best Val Acc = 0.6933, best Val AUROC = 0.7019\n",
            "\n",
            " → lr=1e-03, dropout=0.2, img2txt_mult=2.0, txt2img_mult=0.5 → best Val F1 = 0.7416, best Val Acc = 0.6933, best Val AUROC = 0.7019\n",
            "\n",
            " → lr=1e-03, dropout=0.2, img2txt_mult=2.0, txt2img_mult=1.0 → best Val F1 = 0.7253, best Val Acc = 0.7067, best Val AUROC = 0.7073\n",
            "\n",
            " → lr=1e-03, dropout=0.2, img2txt_mult=2.0, txt2img_mult=2.0 → best Val F1 = 0.7160, best Val Acc = 0.6933, best Val AUROC = 0.6976\n",
            "\n",
            " → lr=1e-03, dropout=0.2, img2txt_mult=2.0, txt2img_mult=5.0 → best Val F1 = 0.7097, best Val Acc = 0.6933, best Val AUROC = 0.6955\n",
            "\n",
            " → lr=1e-03, dropout=0.2, img2txt_mult=3.0, txt2img_mult=0.5 → best Val F1 = 0.7143, best Val Acc = 0.7067, best Val AUROC = 0.7083\n",
            "\n",
            " → lr=1e-03, dropout=0.2, img2txt_mult=3.0, txt2img_mult=1.0 → best Val F1 = 0.7234, best Val Acc = 0.7067, best Val AUROC = 0.7073\n",
            "\n",
            " → lr=1e-03, dropout=0.2, img2txt_mult=3.0, txt2img_mult=2.0 → best Val F1 = 0.7111, best Val Acc = 0.6667, best Val AUROC = 0.6688\n",
            "\n",
            " → lr=1e-03, dropout=0.2, img2txt_mult=3.0, txt2img_mult=5.0 → best Val F1 = 0.7292, best Val Acc = 0.6933, best Val AUROC = 0.6987\n",
            "\n",
            " → lr=1e-03, dropout=0.3, img2txt_mult=0.5, txt2img_mult=0.5 → best Val F1 = 0.7160, best Val Acc = 0.6933, best Val AUROC = 0.6976\n",
            "\n",
            " → lr=1e-03, dropout=0.3, img2txt_mult=0.5, txt2img_mult=1.0 → best Val F1 = 0.7160, best Val Acc = 0.6933, best Val AUROC = 0.6976\n",
            "\n",
            " → lr=1e-03, dropout=0.3, img2txt_mult=0.5, txt2img_mult=2.0 → best Val F1 = 0.7126, best Val Acc = 0.6800, best Val AUROC = 0.6816\n",
            "\n",
            " → lr=1e-03, dropout=0.3, img2txt_mult=0.5, txt2img_mult=5.0 → best Val F1 = 0.7273, best Val Acc = 0.6933, best Val AUROC = 0.6902\n",
            "\n",
            " → lr=1e-03, dropout=0.3, img2txt_mult=1.0, txt2img_mult=0.5 → best Val F1 = 0.7470, best Val Acc = 0.7200, best Val AUROC = 0.7254\n",
            "\n",
            " → lr=1e-03, dropout=0.3, img2txt_mult=1.0, txt2img_mult=1.0 → best Val F1 = 0.7059, best Val Acc = 0.6800, best Val AUROC = 0.6806\n",
            "\n",
            " → lr=1e-03, dropout=0.3, img2txt_mult=1.0, txt2img_mult=2.0 → best Val F1 = 0.7234, best Val Acc = 0.6933, best Val AUROC = 0.6987\n",
            "\n",
            " → lr=1e-03, dropout=0.3, img2txt_mult=1.0, txt2img_mult=5.0 → best Val F1 = 0.7158, best Val Acc = 0.6933, best Val AUROC = 0.6966\n",
            "\n",
            " → lr=1e-03, dropout=0.3, img2txt_mult=2.0, txt2img_mult=0.5 → best Val F1 = 0.7312, best Val Acc = 0.7067, best Val AUROC = 0.7083\n",
            "\n",
            " → lr=1e-03, dropout=0.3, img2txt_mult=2.0, txt2img_mult=1.0 → best Val F1 = 0.6966, best Val Acc = 0.6933, best Val AUROC = 0.6944\n",
            "\n",
            " → lr=1e-03, dropout=0.3, img2txt_mult=2.0, txt2img_mult=2.0 → best Val F1 = 0.7071, best Val Acc = 0.6800, best Val AUROC = 0.6827\n",
            "\n",
            " → lr=1e-03, dropout=0.3, img2txt_mult=2.0, txt2img_mult=5.0 → best Val F1 = 0.7609, best Val Acc = 0.7067, best Val AUROC = 0.7169\n",
            "\n",
            " → lr=1e-03, dropout=0.3, img2txt_mult=3.0, txt2img_mult=0.5 → best Val F1 = 0.7381, best Val Acc = 0.7067, best Val AUROC = 0.7126\n",
            "\n",
            " → lr=1e-03, dropout=0.3, img2txt_mult=3.0, txt2img_mult=1.0 → best Val F1 = 0.7089, best Val Acc = 0.6933, best Val AUROC = 0.6966\n",
            "\n",
            " → lr=1e-03, dropout=0.3, img2txt_mult=3.0, txt2img_mult=2.0 → best Val F1 = 0.7143, best Val Acc = 0.6933, best Val AUROC = 0.6955\n",
            "\n",
            " → lr=1e-03, dropout=0.3, img2txt_mult=3.0, txt2img_mult=5.0 → best Val F1 = 0.7234, best Val Acc = 0.7067, best Val AUROC = 0.7083\n",
            "\n",
            " → lr=1e-04, dropout=0.1, img2txt_mult=0.5, txt2img_mult=0.5 → best Val F1 = 0.6842, best Val Acc = 0.6800, best Val AUROC = 0.6816\n",
            "\n",
            " → lr=1e-04, dropout=0.1, img2txt_mult=0.5, txt2img_mult=1.0 → best Val F1 = 0.6753, best Val Acc = 0.6667, best Val AUROC = 0.6688\n",
            "\n",
            " → lr=1e-04, dropout=0.1, img2txt_mult=0.5, txt2img_mult=2.0 → best Val F1 = 0.6914, best Val Acc = 0.6667, best Val AUROC = 0.6709\n",
            "\n",
            " → lr=1e-04, dropout=0.1, img2txt_mult=0.5, txt2img_mult=5.0 → best Val F1 = 0.6835, best Val Acc = 0.6800, best Val AUROC = 0.6806\n",
            "\n",
            " → lr=1e-04, dropout=0.1, img2txt_mult=1.0, txt2img_mult=0.5 → best Val F1 = 0.6988, best Val Acc = 0.6667, best Val AUROC = 0.6720\n",
            "\n",
            " → lr=1e-04, dropout=0.1, img2txt_mult=1.0, txt2img_mult=1.0 → best Val F1 = 0.6750, best Val Acc = 0.6667, best Val AUROC = 0.6635\n",
            "\n",
            " → lr=1e-04, dropout=0.1, img2txt_mult=1.0, txt2img_mult=2.0 → best Val F1 = 0.6923, best Val Acc = 0.6800, best Val AUROC = 0.6827\n",
            "\n",
            " → lr=1e-04, dropout=0.1, img2txt_mult=1.0, txt2img_mult=5.0 → best Val F1 = 0.7143, best Val Acc = 0.6933, best Val AUROC = 0.6934\n",
            "\n",
            " → lr=1e-04, dropout=0.1, img2txt_mult=2.0, txt2img_mult=0.5 → best Val F1 = 0.7000, best Val Acc = 0.6800, best Val AUROC = 0.6838\n",
            "\n",
            " → lr=1e-04, dropout=0.1, img2txt_mult=2.0, txt2img_mult=1.0 → best Val F1 = 0.7229, best Val Acc = 0.6933, best Val AUROC = 0.6987\n",
            "\n",
            " → lr=1e-04, dropout=0.1, img2txt_mult=2.0, txt2img_mult=2.0 → best Val F1 = 0.7209, best Val Acc = 0.7067, best Val AUROC = 0.7094\n",
            "\n",
            " → lr=1e-04, dropout=0.1, img2txt_mult=2.0, txt2img_mult=5.0 → best Val F1 = 0.7013, best Val Acc = 0.6933, best Val AUROC = 0.6955\n",
            "\n",
            " → lr=1e-04, dropout=0.1, img2txt_mult=3.0, txt2img_mult=0.5 → best Val F1 = 0.7000, best Val Acc = 0.6800, best Val AUROC = 0.6838\n",
            "\n",
            " → lr=1e-04, dropout=0.1, img2txt_mult=3.0, txt2img_mult=1.0 → best Val F1 = 0.7089, best Val Acc = 0.6933, best Val AUROC = 0.6966\n",
            "\n",
            " → lr=1e-04, dropout=0.1, img2txt_mult=3.0, txt2img_mult=2.0 → best Val F1 = 0.7000, best Val Acc = 0.6800, best Val AUROC = 0.6838\n",
            "\n",
            " → lr=1e-04, dropout=0.1, img2txt_mult=3.0, txt2img_mult=5.0 → best Val F1 = 0.7250, best Val Acc = 0.7067, best Val AUROC = 0.7105\n",
            "\n",
            " → lr=1e-04, dropout=0.2, img2txt_mult=0.5, txt2img_mult=0.5 → best Val F1 = 0.7143, best Val Acc = 0.6800, best Val AUROC = 0.6859\n",
            "\n",
            " → lr=1e-04, dropout=0.2, img2txt_mult=0.5, txt2img_mult=1.0 → best Val F1 = 0.6667, best Val Acc = 0.6667, best Val AUROC = 0.6656\n",
            "\n",
            " → lr=1e-04, dropout=0.2, img2txt_mult=0.5, txt2img_mult=2.0 → best Val F1 = 0.6753, best Val Acc = 0.6667, best Val AUROC = 0.6688\n",
            "\n",
            " → lr=1e-04, dropout=0.2, img2txt_mult=0.5, txt2img_mult=5.0 → best Val F1 = 0.7105, best Val Acc = 0.7067, best Val AUROC = 0.7083\n",
            "\n",
            " → lr=1e-04, dropout=0.2, img2txt_mult=1.0, txt2img_mult=0.5 → best Val F1 = 0.6667, best Val Acc = 0.6800, best Val AUROC = 0.6774\n",
            "\n",
            " → lr=1e-04, dropout=0.2, img2txt_mult=1.0, txt2img_mult=1.0 → best Val F1 = 0.7000, best Val Acc = 0.6800, best Val AUROC = 0.6795\n",
            "\n",
            " → lr=1e-04, dropout=0.2, img2txt_mult=1.0, txt2img_mult=2.0 → best Val F1 = 0.6914, best Val Acc = 0.6800, best Val AUROC = 0.6816\n",
            "\n",
            " → lr=1e-04, dropout=0.2, img2txt_mult=1.0, txt2img_mult=5.0 → best Val F1 = 0.7013, best Val Acc = 0.6933, best Val AUROC = 0.6955\n",
            "\n",
            " → lr=1e-04, dropout=0.2, img2txt_mult=2.0, txt2img_mult=0.5 → best Val F1 = 0.6842, best Val Acc = 0.6800, best Val AUROC = 0.6816\n",
            "\n",
            " → lr=1e-04, dropout=0.2, img2txt_mult=2.0, txt2img_mult=1.0 → best Val F1 = 0.6923, best Val Acc = 0.6800, best Val AUROC = 0.6827\n",
            "\n",
            " → lr=1e-04, dropout=0.2, img2txt_mult=2.0, txt2img_mult=2.0 → best Val F1 = 0.6753, best Val Acc = 0.6667, best Val AUROC = 0.6688\n",
            "\n",
            " → lr=1e-04, dropout=0.2, img2txt_mult=2.0, txt2img_mult=5.0 → best Val F1 = 0.7250, best Val Acc = 0.7067, best Val AUROC = 0.7105\n",
            "\n",
            " → lr=1e-04, dropout=0.2, img2txt_mult=3.0, txt2img_mult=0.5 → best Val F1 = 0.6667, best Val Acc = 0.6800, best Val AUROC = 0.6795\n",
            "\n",
            " → lr=1e-04, dropout=0.2, img2txt_mult=3.0, txt2img_mult=1.0 → best Val F1 = 0.6579, best Val Acc = 0.6667, best Val AUROC = 0.6667\n",
            "\n",
            " → lr=1e-04, dropout=0.2, img2txt_mult=3.0, txt2img_mult=2.0 → best Val F1 = 0.7059, best Val Acc = 0.6800, best Val AUROC = 0.6827\n",
            "\n",
            " → lr=1e-04, dropout=0.2, img2txt_mult=3.0, txt2img_mult=5.0 → best Val F1 = 0.6842, best Val Acc = 0.6800, best Val AUROC = 0.6816\n",
            "\n",
            " → lr=1e-04, dropout=0.3, img2txt_mult=0.5, txt2img_mult=0.5 → best Val F1 = 0.6582, best Val Acc = 0.6667, best Val AUROC = 0.6645\n",
            "\n",
            " → lr=1e-04, dropout=0.3, img2txt_mult=0.5, txt2img_mult=1.0 → best Val F1 = 0.6667, best Val Acc = 0.6800, best Val AUROC = 0.6795\n",
            "\n",
            " → lr=1e-04, dropout=0.3, img2txt_mult=0.5, txt2img_mult=2.0 → best Val F1 = 0.6947, best Val Acc = 0.6800, best Val AUROC = 0.6827\n",
            "\n",
            " → lr=1e-04, dropout=0.3, img2txt_mult=0.5, txt2img_mult=5.0 → best Val F1 = 0.6667, best Val Acc = 0.6800, best Val AUROC = 0.6784\n",
            "\n",
            " → lr=1e-04, dropout=0.3, img2txt_mult=1.0, txt2img_mult=0.5 → best Val F1 = 0.7368, best Val Acc = 0.6667, best Val AUROC = 0.6784\n",
            "\n",
            " → lr=1e-04, dropout=0.3, img2txt_mult=1.0, txt2img_mult=1.0 → best Val F1 = 0.6829, best Val Acc = 0.6800, best Val AUROC = 0.6784\n",
            "\n",
            " → lr=1e-04, dropout=0.3, img2txt_mult=1.0, txt2img_mult=2.0 → best Val F1 = 0.6977, best Val Acc = 0.6933, best Val AUROC = 0.6880\n",
            "\n",
            " → lr=1e-04, dropout=0.3, img2txt_mult=1.0, txt2img_mult=5.0 → best Val F1 = 0.7229, best Val Acc = 0.6933, best Val AUROC = 0.6987\n",
            "\n",
            " → lr=1e-04, dropout=0.3, img2txt_mult=2.0, txt2img_mult=0.5 → best Val F1 = 0.7013, best Val Acc = 0.6933, best Val AUROC = 0.6955\n",
            "\n",
            " → lr=1e-04, dropout=0.3, img2txt_mult=2.0, txt2img_mult=1.0 → best Val F1 = 0.7407, best Val Acc = 0.7200, best Val AUROC = 0.7244\n",
            "\n",
            " → lr=1e-04, dropout=0.3, img2txt_mult=2.0, txt2img_mult=2.0 → best Val F1 = 0.7126, best Val Acc = 0.6800, best Val AUROC = 0.6838\n",
            "\n",
            " → lr=1e-04, dropout=0.3, img2txt_mult=2.0, txt2img_mult=5.0 → best Val F1 = 0.6750, best Val Acc = 0.6667, best Val AUROC = 0.6677\n",
            "\n",
            " → lr=1e-04, dropout=0.3, img2txt_mult=3.0, txt2img_mult=0.5 → best Val F1 = 0.6933, best Val Acc = 0.6933, best Val AUROC = 0.6944\n",
            "\n",
            " → lr=1e-04, dropout=0.3, img2txt_mult=3.0, txt2img_mult=1.0 → best Val F1 = 0.7073, best Val Acc = 0.6800, best Val AUROC = 0.6848\n",
            "\n",
            " → lr=1e-04, dropout=0.3, img2txt_mult=3.0, txt2img_mult=2.0 → best Val F1 = 0.6757, best Val Acc = 0.6800, best Val AUROC = 0.6806\n",
            "\n",
            " → lr=1e-04, dropout=0.3, img2txt_mult=3.0, txt2img_mult=5.0 → best Val F1 = 0.7179, best Val Acc = 0.7067, best Val AUROC = 0.7094\n",
            "\n",
            " → lr=1e-05, dropout=0.1, img2txt_mult=0.5, txt2img_mult=0.5 → best Val F1 = 0.5641, best Val Acc = 0.5733, best Val AUROC = 0.5705\n",
            "\n",
            " → lr=1e-05, dropout=0.1, img2txt_mult=0.5, txt2img_mult=1.0 → best Val F1 = 0.5714, best Val Acc = 0.6133, best Val AUROC = 0.6079\n",
            "\n",
            " → lr=1e-05, dropout=0.1, img2txt_mult=0.5, txt2img_mult=2.0 → best Val F1 = 0.6479, best Val Acc = 0.6667, best Val AUROC = 0.6656\n",
            "\n",
            " → lr=1e-05, dropout=0.1, img2txt_mult=0.5, txt2img_mult=5.0 → best Val F1 = 0.6757, best Val Acc = 0.6800, best Val AUROC = 0.6806\n",
            "\n",
            " → lr=1e-05, dropout=0.1, img2txt_mult=1.0, txt2img_mult=0.5 → best Val F1 = 0.5507, best Val Acc = 0.5867, best Val AUROC = 0.5844\n",
            "\n",
            " → lr=1e-05, dropout=0.1, img2txt_mult=1.0, txt2img_mult=1.0 → best Val F1 = 0.5833, best Val Acc = 0.6133, best Val AUROC = 0.6111\n",
            "\n",
            " → lr=1e-05, dropout=0.1, img2txt_mult=1.0, txt2img_mult=2.0 → best Val F1 = 0.6316, best Val Acc = 0.6533, best Val AUROC = 0.6517\n",
            "\n",
            " → lr=1e-05, dropout=0.1, img2txt_mult=1.0, txt2img_mult=5.0 → best Val F1 = 0.6585, best Val Acc = 0.6667, best Val AUROC = 0.6667\n",
            "\n",
            " → lr=1e-05, dropout=0.1, img2txt_mult=2.0, txt2img_mult=0.5 → best Val F1 = 0.6400, best Val Acc = 0.6400, best Val AUROC = 0.6410\n",
            "\n",
            " → lr=1e-05, dropout=0.1, img2txt_mult=2.0, txt2img_mult=1.0 → best Val F1 = 0.5882, best Val Acc = 0.6267, best Val AUROC = 0.6239\n",
            "\n",
            " → lr=1e-05, dropout=0.1, img2txt_mult=2.0, txt2img_mult=2.0 → best Val F1 = 0.6133, best Val Acc = 0.6267, best Val AUROC = 0.6239\n",
            "\n",
            " → lr=1e-05, dropout=0.1, img2txt_mult=2.0, txt2img_mult=5.0 → best Val F1 = 0.6849, best Val Acc = 0.6933, best Val AUROC = 0.6934\n",
            "\n",
            " → lr=1e-05, dropout=0.1, img2txt_mult=3.0, txt2img_mult=0.5 → best Val F1 = 0.6486, best Val Acc = 0.6533, best Val AUROC = 0.6538\n",
            "\n",
            " → lr=1e-05, dropout=0.1, img2txt_mult=3.0, txt2img_mult=1.0 → best Val F1 = 0.6269, best Val Acc = 0.6667, best Val AUROC = 0.6635\n",
            "\n",
            " → lr=1e-05, dropout=0.1, img2txt_mult=3.0, txt2img_mult=2.0 → best Val F1 = 0.6286, best Val Acc = 0.6533, best Val AUROC = 0.6517\n",
            "\n",
            " → lr=1e-05, dropout=0.1, img2txt_mult=3.0, txt2img_mult=5.0 → best Val F1 = 0.6579, best Val Acc = 0.6667, best Val AUROC = 0.6656\n",
            "\n",
            " → lr=1e-05, dropout=0.2, img2txt_mult=0.5, txt2img_mult=0.5 → best Val F1 = 0.5432, best Val Acc = 0.5467, best Val AUROC = 0.5449\n",
            "\n",
            " → lr=1e-05, dropout=0.2, img2txt_mult=0.5, txt2img_mult=1.0 → best Val F1 = 0.5714, best Val Acc = 0.6133, best Val AUROC = 0.6090\n",
            "\n",
            " → lr=1e-05, dropout=0.2, img2txt_mult=0.5, txt2img_mult=2.0 → best Val F1 = 0.5753, best Val Acc = 0.6133, best Val AUROC = 0.6100\n",
            "\n",
            " → lr=1e-05, dropout=0.2, img2txt_mult=0.5, txt2img_mult=5.0 → best Val F1 = 0.6905, best Val Acc = 0.6533, best Val AUROC = 0.6592\n",
            "\n",
            " → lr=1e-05, dropout=0.2, img2txt_mult=1.0, txt2img_mult=0.5 → best Val F1 = 0.5714, best Val Acc = 0.5733, best Val AUROC = 0.5705\n",
            "\n",
            " → lr=1e-05, dropout=0.2, img2txt_mult=1.0, txt2img_mult=1.0 → best Val F1 = 0.5797, best Val Acc = 0.6133, best Val AUROC = 0.6111\n",
            "\n",
            " → lr=1e-05, dropout=0.2, img2txt_mult=1.0, txt2img_mult=2.0 → best Val F1 = 0.6216, best Val Acc = 0.6267, best Val AUROC = 0.6271\n",
            "\n",
            " → lr=1e-05, dropout=0.2, img2txt_mult=1.0, txt2img_mult=5.0 → best Val F1 = 0.6667, best Val Acc = 0.6533, best Val AUROC = 0.6560\n",
            "\n",
            " → lr=1e-05, dropout=0.2, img2txt_mult=2.0, txt2img_mult=0.5 → best Val F1 = 0.5542, best Val Acc = 0.5600, best Val AUROC = 0.5577\n",
            "\n",
            " → lr=1e-05, dropout=0.2, img2txt_mult=2.0, txt2img_mult=1.0 → best Val F1 = 0.6000, best Val Acc = 0.6267, best Val AUROC = 0.6250\n",
            "\n",
            " → lr=1e-05, dropout=0.2, img2txt_mult=2.0, txt2img_mult=2.0 → best Val F1 = 0.6087, best Val Acc = 0.6400, best Val AUROC = 0.6378\n",
            "\n",
            " → lr=1e-05, dropout=0.2, img2txt_mult=2.0, txt2img_mult=5.0 → best Val F1 = 0.6329, best Val Acc = 0.6267, best Val AUROC = 0.6271\n",
            "\n",
            " → lr=1e-05, dropout=0.2, img2txt_mult=3.0, txt2img_mult=0.5 → best Val F1 = 0.5783, best Val Acc = 0.6000, best Val AUROC = 0.5972\n",
            "\n",
            " → lr=1e-05, dropout=0.2, img2txt_mult=3.0, txt2img_mult=1.0 → best Val F1 = 0.5676, best Val Acc = 0.6000, best Val AUROC = 0.5962\n",
            "\n",
            " → lr=1e-05, dropout=0.2, img2txt_mult=3.0, txt2img_mult=2.0 → best Val F1 = 0.6061, best Val Acc = 0.6533, best Val AUROC = 0.6496\n",
            "\n",
            " → lr=1e-05, dropout=0.2, img2txt_mult=3.0, txt2img_mult=5.0 → best Val F1 = 0.6914, best Val Acc = 0.6800, best Val AUROC = 0.6806\n",
            "\n",
            " → lr=1e-05, dropout=0.3, img2txt_mult=0.5, txt2img_mult=0.5 → best Val F1 = 0.5854, best Val Acc = 0.5733, best Val AUROC = 0.5705\n",
            "\n",
            " → lr=1e-05, dropout=0.3, img2txt_mult=0.5, txt2img_mult=1.0 → best Val F1 = 0.5797, best Val Acc = 0.6133, best Val AUROC = 0.6111\n",
            "\n",
            " → lr=1e-05, dropout=0.3, img2txt_mult=0.5, txt2img_mult=2.0 → best Val F1 = 0.5679, best Val Acc = 0.6133, best Val AUROC = 0.6068\n",
            "\n",
            " → lr=1e-05, dropout=0.3, img2txt_mult=0.5, txt2img_mult=5.0 → best Val F1 = 0.6575, best Val Acc = 0.6667, best Val AUROC = 0.6667\n",
            "\n",
            " → lr=1e-05, dropout=0.3, img2txt_mult=1.0, txt2img_mult=0.5 → best Val F1 = 0.5679, best Val Acc = 0.5600, best Val AUROC = 0.5588\n",
            "\n",
            " → lr=1e-05, dropout=0.3, img2txt_mult=1.0, txt2img_mult=1.0 → best Val F1 = 0.5588, best Val Acc = 0.6000, best Val AUROC = 0.5972\n",
            "\n",
            " → lr=1e-05, dropout=0.3, img2txt_mult=1.0, txt2img_mult=2.0 → best Val F1 = 0.5797, best Val Acc = 0.6267, best Val AUROC = 0.6207\n",
            "\n",
            " → lr=1e-05, dropout=0.3, img2txt_mult=1.0, txt2img_mult=5.0 → best Val F1 = 0.6512, best Val Acc = 0.6400, best Val AUROC = 0.6389\n",
            "\n",
            " → lr=1e-05, dropout=0.3, img2txt_mult=2.0, txt2img_mult=0.5 → best Val F1 = 0.5641, best Val Acc = 0.5600, best Val AUROC = 0.5609\n",
            "\n",
            " → lr=1e-05, dropout=0.3, img2txt_mult=2.0, txt2img_mult=1.0 → best Val F1 = 0.5915, best Val Acc = 0.6133, best Val AUROC = 0.6122\n",
            "\n",
            " → lr=1e-05, dropout=0.3, img2txt_mult=2.0, txt2img_mult=2.0 → best Val F1 = 0.6000, best Val Acc = 0.6267, best Val AUROC = 0.6250\n",
            "\n",
            " → lr=1e-05, dropout=0.3, img2txt_mult=2.0, txt2img_mult=5.0 → best Val F1 = 0.6842, best Val Acc = 0.6800, best Val AUROC = 0.6816\n",
            "\n",
            " → lr=1e-05, dropout=0.3, img2txt_mult=3.0, txt2img_mult=0.5 → best Val F1 = 0.5867, best Val Acc = 0.5867, best Val AUROC = 0.5876\n",
            "\n",
            " → lr=1e-05, dropout=0.3, img2txt_mult=3.0, txt2img_mult=1.0 → best Val F1 = 0.5915, best Val Acc = 0.6267, best Val AUROC = 0.6229\n",
            "\n",
            " → lr=1e-05, dropout=0.3, img2txt_mult=3.0, txt2img_mult=2.0 → best Val F1 = 0.5846, best Val Acc = 0.6400, best Val AUROC = 0.6357\n",
            "\n",
            " → lr=1e-05, dropout=0.3, img2txt_mult=3.0, txt2img_mult=5.0 → best Val F1 = 0.6757, best Val Acc = 0.6800, best Val AUROC = 0.6806\n",
            "\n",
            ">>> Best config by F1: lr=1e-03, dropout=0.3, img2txt_mult=2.0, txt2img_mult=5.0 with Val F1=0.7609 (Acc=0.7067, AUROC=0.7169)\n"
          ]
        }
      ]
    }
  ]
}