{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9abef57ce3764b98812b5d90fbc514e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e450cc03c0ec4e5ca9c5dfc5c70583d8",
              "IPY_MODEL_ed7bf50202fa4035ab2b230061422fb4",
              "IPY_MODEL_999baa0701cc49f0b655cdeec24ba749"
            ],
            "layout": "IPY_MODEL_68d3f809d5f54c14968850fed060a970"
          }
        },
        "e450cc03c0ec4e5ca9c5dfc5c70583d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99242e787adb4aba93edf37a49ea32e3",
            "placeholder": "​",
            "style": "IPY_MODEL_4edd75ef13e948e980638b1aae89f504",
            "value": "Extracting features: 100%"
          }
        },
        "ed7bf50202fa4035ab2b230061422fb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa6a5374f4b94965ac5f2f25972e49c0",
            "max": 60,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_830a7274b42e4c33995a873582ecb95d",
            "value": 60
          }
        },
        "999baa0701cc49f0b655cdeec24ba749": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfa6992ab74f41afb50e401395963197",
            "placeholder": "​",
            "style": "IPY_MODEL_63e4332755f84821a7948543ea2843fc",
            "value": " 60/60 [00:06&lt;00:00,  9.20batch/s]"
          }
        },
        "68d3f809d5f54c14968850fed060a970": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99242e787adb4aba93edf37a49ea32e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4edd75ef13e948e980638b1aae89f504": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa6a5374f4b94965ac5f2f25972e49c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "830a7274b42e4c33995a873582ecb95d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dfa6992ab74f41afb50e401395963197": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63e4332755f84821a7948543ea2843fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Dense_Closed.ipynb\n",
        "\n",
        "Automatically generated by Colab.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1RAl-O0E1Ixj8rMU0lUYeF2ToSIOMOtiu\n",
        "\"\"\"\n",
        "\n",
        "# Install necessary packages\n",
        "!pip install datasets\n",
        "# pip install focal-loss --upgrade\n",
        "# import focal_loss\n",
        "\n",
        "import os\n",
        "import re\n",
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from datasets import Dataset, DatasetDict\n",
        "import os\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Ensure NLTK data is downloaded for BLEU scoring\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def set_seed(seed_value=42):\n",
        "    \"\"\"Set seed for reproducibility for PyTorch and NumPy.\n",
        "\n",
        "    Args:\n",
        "        seed_value (int): The seed value to set for random number generators.\n",
        "    \"\"\"\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "path_project = '/content/drive/MyDrive/Project'\n",
        "\n",
        "# 2) Load + preprocess + split\n",
        "def vqa_rad_setup(path_project):\n",
        "    json_file = \"VQA_RAD Dataset Public.json\"\n",
        "    image_folder = \"VQA_RAD Image Folder\"\n",
        "    json_path = os.path.join(path_project, json_file)\n",
        "    image_dir  = os.path.join(path_project, image_folder)\n",
        "\n",
        "\n",
        "\n",
        "    df = pd.read_json(json_path)\n",
        "    df['image_path'] = df['image_name'].apply(lambda fn: os.path.join(image_dir, fn))\n",
        "\n",
        "    unique_images  = df['image_path'].nunique()\n",
        "    print(f\"Number of unique images: {unique_images}\")\n",
        "\n",
        "\n",
        "    # 2) Normalize and filter to only CLOSED‑type questions\n",
        "    df['answer_type']   = df['answer_type'].str.strip().str.lower()\n",
        "    df['question_type'] = df['question_type'].str.strip().str.lower()\n",
        "    df['answer']        = df['answer'].str.strip().str.lower()\n",
        "    df_closed = df[df['answer_type']=='closed'].copy()\n",
        "    print(\"Closed-QA rows:\", len(df_closed))\n",
        "\n",
        "    # — 3) original closed-QA (organ column will be NaN here)\n",
        "    df_closed_qa = df_closed[['image_path','question','answer']].copy()\n",
        "    df_closed_qa['image_organ'] = pd.NA\n",
        "\n",
        "    # — 4) build the “template” for organ & question_type\n",
        "    df_present = (\n",
        "        df_closed[['image_path','image_organ','question_type']]  # include question_type\n",
        "          .drop_duplicates(subset='image_path')\n",
        "          .copy()\n",
        "    )\n",
        "\n",
        "    # — 5a) QA variant #1: ask about the question type\n",
        "    df_q1 = df_present.assign(\n",
        "        question = \"What is the type of the question?\",\n",
        "        answer   = df_present['question_type']\n",
        "    )[['image_path','question','answer','image_organ']]\n",
        "\n",
        "    # — 5b) QA variant #2: ask about the organ\n",
        "    df_q2 = df_present.assign(\n",
        "        question = \"Which organ is shown?\",\n",
        "        answer   = df_present['image_organ']\n",
        "    )[['image_path','question','answer','image_organ']]\n",
        "\n",
        "    # — 6) combine all three sets and shuffle\n",
        "    df_all = pd.concat([df_closed_qa, df_q1, df_q2], ignore_index=True)\n",
        "    df_all = df_all.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "    print(\"Total QA rows:\", len(df_all))\n",
        "\n",
        "    return df_all\n",
        "\n",
        "df_binary = vqa_rad_setup(path_project)\n",
        "\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 3) Instantiate your MedCLIP processor\n",
        "##model_name = \"openai/clip-vit-base-patch32\"  # You can choose different CLIP model variants\n",
        "#processor = CLIPProcessor.from_pretrained(model_name)\n",
        "\n",
        "\n",
        "def densenet_processor():\n",
        "    return transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(\n",
        "            mean=[0.485, 0.456, 0.406],\n",
        "            std=[0.229, 0.224, 0.225]\n",
        "        )\n",
        "    ])\n",
        "\n",
        "def transform_image_pre(image_path):\n",
        "    image = Image.open(image_path)\n",
        "    if image.mode != 'RGB':\n",
        "        image = image.convert('RGB')\n",
        "    return densenet_processor()(image)\n",
        "\n",
        "\n",
        "# 6) Batch‑load all train images into one big tensor\n",
        "image_tensors = []\n",
        "failed_images = []\n",
        "\n",
        "for img_path in tqdm(df_binary['image_path'], desc=\"Processing images\"):\n",
        "    try:\n",
        "        tensor = transform_image_pre(img_path)\n",
        "        image_tensors.append(tensor)\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Skipped {img_path}: {e}\")\n",
        "        failed_images.append(img_path)\n",
        "\n",
        "full_image_tensor = torch.stack(image_tensors, dim=0)\n",
        "print(f\"\\nProcessed {len(image_tensors)} images; skipped {len(failed_images)}.\")\n",
        "print(\"full_image_tensor.shape =\", full_image_tensor.shape)\n",
        "\n",
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.checkpoint as cp\n",
        "from collections import OrderedDict\n",
        "\n",
        "\n",
        "\n",
        "def _bn_function_factory(norm, relu, conv):\n",
        "    def bn_function(*inputs):\n",
        "        concated_features = torch.cat(inputs, 1)\n",
        "        bottleneck_output = conv(relu(norm(concated_features)))\n",
        "        return bottleneck_output\n",
        "\n",
        "    return bn_function\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XP9cKoSL1xR3",
        "outputId": "04b13a1d-0b58-4045-c264-3d8a01ed754f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Number of unique images: 314\n",
            "Closed-QA rows: 1299\n",
            "Total QA rows: 1899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing images: 100%|██████████| 1899/1899 [00:28<00:00, 67.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processed 1899 images; skipped 0.\n",
            "full_image_tensor.shape = torch.Size([1899, 3, 224, 224])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "# 1) Device & tokenizer\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "print(f\"Loaded BERT tokenizer with vocab size: {tokenizer.vocab_size}\")\n",
        "\n",
        "question_lengths = [len(tokenizer(q, add_special_tokens=True)['input_ids']) for q in df_binary['question']]\n",
        "answer_lengths   = [len(tokenizer(a, add_special_tokens=True)['input_ids']) for a in df_binary['answer']]\n",
        "import numpy as np\n",
        "\n",
        "print(f\"Question lengths: min={np.min(question_lengths)}, max={np.max(question_lengths)}, mean={np.mean(question_lengths):.1f}, 95th percentile={np.percentile(question_lengths, 95)}\")\n",
        "print(f\"Answer lengths:   min={np.min(answer_lengths)}, max={np.max(answer_lengths)}, mean={np.mean(answer_lengths):.1f}, 95th percentile={np.percentile(answer_lengths, 95)}\")\n",
        "\n",
        "\n",
        "# 2) Max lengths\n",
        "max_question_length = 28\n",
        "max_answer_length   = 9\n",
        "\n",
        "# 3) Prepare lists\n",
        "q_input_ids, q_attention_masks = [], []\n",
        "a_input_ids, a_attention_masks = [], []\n",
        "\n",
        "# 4) Loop over your DataFrame\n",
        "for q, a in zip(df_binary['question'], df_binary['answer']):\n",
        "    # tokenize question\n",
        "    q_tok = tokenizer(\n",
        "        q,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        max_length=max_question_length,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    q_input_ids.append(q_tok['input_ids'].squeeze(0))         # [seq_len]\n",
        "    q_attention_masks.append(q_tok['attention_mask'].squeeze(0))\n",
        "\n",
        "    # tokenize answer\n",
        "    a_tok = tokenizer(\n",
        "        a,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        max_length=max_answer_length,\n",
        "        return_tensors=\"pt\",\n",
        "        add_special_tokens=True\n",
        "    )\n",
        "    a_input_ids.append(a_tok['input_ids'].squeeze(0))         # [seq_len]\n",
        "    a_attention_masks.append(a_tok['attention_mask'].squeeze(0))\n",
        "\n",
        "# 5) Stack into big tensors\n",
        "Question_ids   = torch.stack(q_input_ids)        # [N, max_question_length]\n",
        "Question_mask  = torch.stack(q_attention_masks)  # [N, max_question_length]\n",
        "Answer_ids     = torch.stack(a_input_ids)        # [N, max_answer_length]\n",
        "Answer_mask    = torch.stack(a_attention_masks)  # [N, max_answer_length]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZhLUeBVCC7Q",
        "outputId": "0f192881-b48a-4364-8da8-9b428058b7ae"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded BERT tokenizer with vocab size: 30522\n",
            "Question lengths: min=6, max=28, mean=10.4, 95th percentile=16.0\n",
            "Answer lengths:   min=3, max=9, mean=3.2, 95th percentile=4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class BiLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, num_layers, dropout):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=emb_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=True,\n",
        "            dropout=dropout if num_layers > 1 else 0.0\n",
        "        )\n",
        "        # project bidirectional hidden to single vector\n",
        "        self.fc = nn.Linear(hidden_dim * 2, hidden_dim)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        # input_ids: [B, T], attention_mask: [B, T]\n",
        "        embeds = self.embedding(input_ids)                      # [B, T, emb_dim]\n",
        "        lengths = attention_mask.sum(dim=1).cpu()               # actual lengths\n",
        "        packed = nn.utils.rnn.pack_padded_sequence(\n",
        "            embeds, lengths, batch_first=True, enforce_sorted=False\n",
        "        )\n",
        "        packed_out, (h_n, _) = self.lstm(packed)\n",
        "        # h_n: [num_layers*2, B, hidden_dim]\n",
        "        # take last forward & backward layers\n",
        "        h_fwd = h_n[-2]                                         # [B, hidden_dim]\n",
        "        h_bwd = h_n[-1]                                         # [B, hidden_dim]\n",
        "        h_cat = torch.cat([h_fwd, h_bwd], dim=1)                # [B, hidden_dim*2]\n",
        "        out = self.fc(h_cat)                                    # [B, hidden_dim]\n",
        "        return out"
      ],
      "metadata": {
        "id": "TQKQ1bKqCH9Q"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "print(tokenizer.vocab_size)\n",
        "\n",
        "#from torchvision.models import densenet121 as tv_densenet121\n",
        "\n",
        "#1) Load the torchvision DenseNet121 (with its pretrained weights)\n",
        "#densenet = tv_densenet121(pretrained=True).to(device).eval()\n",
        "\n",
        "\n",
        "from torchvision.models import densenet169 as tv_densenet169\n",
        "densenet = tv_densenet169(pretrained=True).to(device).eval()\n",
        "\n",
        "# 2) Wrap it for feature extraction just as before\n",
        "feature_extractor = nn.Sequential(\n",
        "    densenet.features,\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.AdaptiveAvgPool2d((1, 1)),\n",
        "    nn.Flatten(start_dim=1),\n",
        ").to(device).eval()\n",
        "\n",
        "# 3) Your BiLSTM instance—make sure you **don't** leave a trailing comma!\n",
        "text_model = BiLSTM(\n",
        "    vocab_size = tokenizer.vocab_size,\n",
        "    emb_dim=256,\n",
        "    hidden_dim=256,\n",
        "    num_layers=2,\n",
        "    dropout=0.3\n",
        ").to(device).eval()  # ← no comma here\n",
        "\n",
        "print(\"📦 Tokenizer vocab size:\", tokenizer.vocab_size)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# 1) Raw‐tensor Dataset & DataLoader\n",
        "batch_size = 64\n",
        "raw_ds     = TensorDataset(full_image_tensor, Question_ids, Question_mask)\n",
        "raw_loader = DataLoader(raw_ds, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "import time\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "def extract_features_and_questions(loader, feature_extractor, text_model, device):\n",
        "    all_img_feats  = []\n",
        "    all_txt_feats  = []\n",
        "    all_q_ids      = []\n",
        "    all_q_mask     = []\n",
        "    total_start    = time.time()\n",
        "\n",
        "\n",
        "    for imgs, q_ids, q_mask in tqdm(loader, desc=\"Extracting features\", unit=\"batch\"):\n",
        "        imgs   = imgs.to(device)\n",
        "        q_ids  = q_ids.to(device)\n",
        "        q_mask = q_mask.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            img_feats = feature_extractor(imgs)\n",
        "            txt_feats = text_model(q_ids, q_mask)\n",
        "\n",
        "        all_img_feats.append(img_feats.cpu())\n",
        "        all_txt_feats.append(txt_feats.cpu())\n",
        "        all_q_ids.append(q_ids.cpu())\n",
        "        all_q_mask.append(q_mask.cpu())\n",
        "\n",
        "    #concatenate everything\n",
        "    image_features = torch.cat(all_img_feats, dim=0)  # [N,1024]\n",
        "    text_features  = torch.cat(all_txt_feats,  dim=0)  # [N,256]\n",
        "    Question_ids   = torch.cat(all_q_ids,      dim=0)  # [N, T_q]\n",
        "    Question_mask  = torch.cat(all_q_mask,     dim=0)  # [N, T_q]\n",
        "\n",
        "    return image_features, text_features, Question_ids, Question_mask\n",
        "\n",
        "# run it\n",
        "image_features, text_features, Question_ids, Question_mask = \\\n",
        "    extract_features_and_questions(raw_loader, feature_extractor, text_model, device)\n",
        "\n",
        "print(\"image_features:\", image_features.shape)  # → [N,1024]\n",
        "print(\"text_features: \", text_features.shape)   # → [N,256]\n",
        "\n",
        "y_train_tensor = Answer_ids\n",
        "\n",
        "# If your model expects decoder inputs shifted right (for teacher forcing),\n",
        "# you can slice:\n",
        "decoder_input_ids = y_train_tensor[:, :-1]   # [N, max_answer_length-1]\n",
        "labels           = y_train_tensor[:, 1:]\n",
        "\n",
        "\n",
        "# 4) Now split & wrap for your classifier\n",
        "N_split = 75\n",
        "Image_train   = image_features[N_split:]       # [train_N, 1024]\n",
        "Image_test    = image_features[:N_split]       # [test_N, 1024]\n",
        "Text_train    = text_features[N_split:]        # [train_N, 256]\n",
        "Text_test     = text_features[:N_split]        # [test_N, 256]\n",
        "Qids_train    = Question_ids[N_split:]         # [train_N, T_q]\n",
        "Qids_test     = Question_ids[:N_split]         # [test_N, T_q]\n",
        "Qmask_train   = Question_mask[N_split:]        # [train_N, T_q]\n",
        "Qmask_test    = Question_mask[:N_split]        # [test_N, T_q]\n",
        "Dec_in_train  = decoder_input_ids[N_split:]        # [train_N, T_a-1]\n",
        "Dec_in_test   = decoder_input_ids[:N_split]        # [test_N, T_a-1]\n",
        "Dec_lab_train = labels[N_split:]           # [train_N, T_a-1]\n",
        "Dec_lab_test  = labels[:N_split]           # [test_N, T_a-1]\n",
        "\n",
        "# 4) Build your TensorDatasets\n",
        "train_ds = TensorDataset(\n",
        "    Image_train,\n",
        "    Text_train,\n",
        "    Qids_train,\n",
        "    Qmask_train,\n",
        "    Dec_in_train,\n",
        "    Dec_lab_train,\n",
        ")\n",
        "test_ds = TensorDataset(\n",
        "    Image_test,\n",
        "    Text_test,\n",
        "    Qids_test,\n",
        "    Qmask_test,\n",
        "    Dec_in_test,\n",
        "    Dec_lab_test,\n",
        ")\n",
        "\n",
        "# 5) Wrap in DataLoaders\n",
        "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=1,  shuffle=False)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "9abef57ce3764b98812b5d90fbc514e7",
            "e450cc03c0ec4e5ca9c5dfc5c70583d8",
            "ed7bf50202fa4035ab2b230061422fb4",
            "999baa0701cc49f0b655cdeec24ba749",
            "68d3f809d5f54c14968850fed060a970",
            "99242e787adb4aba93edf37a49ea32e3",
            "4edd75ef13e948e980638b1aae89f504",
            "fa6a5374f4b94965ac5f2f25972e49c0",
            "830a7274b42e4c33995a873582ecb95d",
            "dfa6992ab74f41afb50e401395963197",
            "63e4332755f84821a7948543ea2843fc"
          ]
        },
        "id": "H9pNyMs1_pPZ",
        "outputId": "f313b855-097d-4ce5-e5fe-5b3de29a84ad"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30522\n",
            "📦 Tokenizer vocab size: 30522\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extracting features:   0%|          | 0/60 [00:00<?, ?batch/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9abef57ce3764b98812b5d90fbc514e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image_features: torch.Size([1899, 1024])\n",
            "text_features:  torch.Size([1899, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bg1G1amMsPmS",
        "outputId": "9587c807-3ac3-4047-877f-cfe4b13a1c2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/50: 100%|██████████| 29/29 [00:01<00:00, 23.94it/s, loss=5.04]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Loss: 8.9853\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 75/75 [00:00<00:00, 165.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-1 score: 0.4222\n",
            "Average ROUGE-2 score: 0.0000\n",
            "Average ROUGE-L score: 0.4222\n",
            "Yes/No question accuracy: 52.1% (25/48) - for analysis only\n",
            "BLEU score: 0.3835\n",
            "ROUGE-1 score: 0.4222\n",
            "ROUGE-2 score: 0.0000\n",
            "ROUGE-L score: 0.4222\n",
            "New best model saved with BLEU score: 0.3835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/50: 100%|██████████| 29/29 [00:01<00:00, 26.28it/s, loss=4.25]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/50, Loss: 5.7906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 75/75 [00:00<00:00, 168.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-1 score: 0.4622\n",
            "Average ROUGE-2 score: 0.0000\n",
            "Average ROUGE-L score: 0.4622\n",
            "Yes/No question accuracy: 52.1% (25/48) - for analysis only\n",
            "BLEU score: 0.4235\n",
            "ROUGE-1 score: 0.4622\n",
            "ROUGE-2 score: 0.0000\n",
            "ROUGE-L score: 0.4622\n",
            "New best model saved with BLEU score: 0.4235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/50: 100%|██████████| 29/29 [00:01<00:00, 24.39it/s, loss=6.32]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/50, Loss: 5.0484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 75/75 [00:00<00:00, 166.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-1 score: 0.5022\n",
            "Average ROUGE-2 score: 0.0000\n",
            "Average ROUGE-L score: 0.5022\n",
            "Yes/No question accuracy: 45.8% (22/48) - for analysis only\n",
            "BLEU score: 0.4635\n",
            "ROUGE-1 score: 0.5022\n",
            "ROUGE-2 score: 0.0000\n",
            "ROUGE-L score: 0.5022\n",
            "New best model saved with BLEU score: 0.4635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/50: 100%|██████████| 29/29 [00:01<00:00, 24.52it/s, loss=3.82]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/50, Loss: 4.4563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 75/75 [00:00<00:00, 164.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-1 score: 0.4489\n",
            "Average ROUGE-2 score: 0.0000\n",
            "Average ROUGE-L score: 0.4489\n",
            "Yes/No question accuracy: 39.6% (19/48) - for analysis only\n",
            "BLEU score: 0.4102\n",
            "ROUGE-1 score: 0.4489\n",
            "ROUGE-2 score: 0.0000\n",
            "ROUGE-L score: 0.4489\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/50: 100%|██████████| 29/29 [00:01<00:00, 26.33it/s, loss=4.16]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/50, Loss: 4.2282\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 75/75 [00:00<00:00, 120.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-1 score: 0.4489\n",
            "Average ROUGE-2 score: 0.0000\n",
            "Average ROUGE-L score: 0.4489\n",
            "Yes/No question accuracy: 39.6% (19/48) - for analysis only\n",
            "BLEU score: 0.4102\n",
            "ROUGE-1 score: 0.4489\n",
            "ROUGE-2 score: 0.0000\n",
            "ROUGE-L score: 0.4489\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/50: 100%|██████████| 29/29 [00:01<00:00, 24.85it/s, loss=5.75]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/50, Loss: 4.0307\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 75/75 [00:00<00:00, 122.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-1 score: 0.4489\n",
            "Average ROUGE-2 score: 0.0000\n",
            "Average ROUGE-L score: 0.4489\n",
            "Yes/No question accuracy: 39.6% (19/48) - for analysis only\n",
            "BLEU score: 0.4102\n",
            "ROUGE-1 score: 0.4489\n",
            "ROUGE-2 score: 0.0000\n",
            "ROUGE-L score: 0.4489\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/50: 100%|██████████| 29/29 [00:01<00:00, 25.16it/s, loss=3.66]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/50, Loss: 3.7458\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 75/75 [00:00<00:00, 164.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-1 score: 0.5689\n",
            "Average ROUGE-2 score: 0.0000\n",
            "Average ROUGE-L score: 0.5689\n",
            "Yes/No question accuracy: 56.2% (27/48) - for analysis only\n",
            "BLEU score: 0.5302\n",
            "ROUGE-1 score: 0.5689\n",
            "ROUGE-2 score: 0.0000\n",
            "ROUGE-L score: 0.5689\n",
            "New best model saved with BLEU score: 0.5302\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/50: 100%|██████████| 29/29 [00:01<00:00, 24.58it/s, loss=3.1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/50, Loss: 3.5859\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 75/75 [00:00<00:00, 161.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-1 score: 0.5022\n",
            "Average ROUGE-2 score: 0.0000\n",
            "Average ROUGE-L score: 0.5022\n",
            "Yes/No question accuracy: 54.2% (26/48) - for analysis only\n",
            "BLEU score: 0.4635\n",
            "ROUGE-1 score: 0.5022\n",
            "ROUGE-2 score: 0.0000\n",
            "ROUGE-L score: 0.5022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/50: 100%|██████████| 29/29 [00:01<00:00, 24.58it/s, loss=3.54]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/50, Loss: 3.4690\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 75/75 [00:00<00:00, 118.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-1 score: 0.5289\n",
            "Average ROUGE-2 score: 0.0000\n",
            "Average ROUGE-L score: 0.5289\n",
            "Yes/No question accuracy: 52.1% (25/48) - for analysis only\n",
            "BLEU score: 0.4902\n",
            "ROUGE-1 score: 0.5289\n",
            "ROUGE-2 score: 0.0000\n",
            "ROUGE-L score: 0.5289\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/50: 100%|██████████| 29/29 [00:01<00:00, 24.98it/s, loss=3.36]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/50, Loss: 3.3933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 75/75 [00:00<00:00, 142.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-1 score: 0.5689\n",
            "Average ROUGE-2 score: 0.0000\n",
            "Average ROUGE-L score: 0.5689\n",
            "Yes/No question accuracy: 58.3% (28/48) - for analysis only\n",
            "BLEU score: 0.5302\n",
            "ROUGE-1 score: 0.5689\n",
            "ROUGE-2 score: 0.0000\n",
            "ROUGE-L score: 0.5689\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/50: 100%|██████████| 29/29 [00:01<00:00, 26.18it/s, loss=3.15]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/50, Loss: 3.1943\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 75/75 [00:00<00:00, 162.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-1 score: 0.5689\n",
            "Average ROUGE-2 score: 0.0000\n",
            "Average ROUGE-L score: 0.5689\n",
            "Yes/No question accuracy: 60.4% (29/48) - for analysis only\n",
            "BLEU score: 0.5302\n",
            "ROUGE-1 score: 0.5689\n",
            "ROUGE-2 score: 0.0000\n",
            "ROUGE-L score: 0.5689\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/50: 100%|██████████| 29/29 [00:01<00:00, 26.02it/s, loss=3.37]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/50, Loss: 3.0995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 75/75 [00:00<00:00, 165.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-1 score: 0.5156\n",
            "Average ROUGE-2 score: 0.0000\n",
            "Average ROUGE-L score: 0.5156\n",
            "Yes/No question accuracy: 52.1% (25/48) - for analysis only\n",
            "BLEU score: 0.4768\n",
            "ROUGE-1 score: 0.5156\n",
            "ROUGE-2 score: 0.0000\n",
            "ROUGE-L score: 0.5156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/50: 100%|██████████| 29/29 [00:01<00:00, 26.12it/s, loss=3.16]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/50, Loss: 3.0164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 75/75 [00:00<00:00, 161.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-1 score: 0.5556\n",
            "Average ROUGE-2 score: 0.0000\n",
            "Average ROUGE-L score: 0.5556\n",
            "Yes/No question accuracy: 54.2% (26/48) - for analysis only\n",
            "BLEU score: 0.5168\n",
            "ROUGE-1 score: 0.5556\n",
            "ROUGE-2 score: 0.0000\n",
            "ROUGE-L score: 0.5556\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/50: 100%|██████████| 29/29 [00:01<00:00, 26.14it/s, loss=3.5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/50, Loss: 2.9543\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 75/75 [00:00<00:00, 165.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-1 score: 0.5822\n",
            "Average ROUGE-2 score: 0.0000\n",
            "Average ROUGE-L score: 0.5822\n",
            "Yes/No question accuracy: 60.4% (29/48) - for analysis only\n",
            "BLEU score: 0.5435\n",
            "ROUGE-1 score: 0.5822\n",
            "ROUGE-2 score: 0.0000\n",
            "ROUGE-L score: 0.5822\n",
            "New best model saved with BLEU score: 0.5435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/50: 100%|██████████| 29/29 [00:01<00:00, 24.22it/s, loss=2.98]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/50, Loss: 2.8345\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 75/75 [00:00<00:00, 161.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-1 score: 0.6222\n",
            "Average ROUGE-2 score: 0.0000\n",
            "Average ROUGE-L score: 0.6222\n",
            "Yes/No question accuracy: 68.8% (33/48) - for analysis only\n",
            "BLEU score: 0.5835\n",
            "ROUGE-1 score: 0.6222\n",
            "ROUGE-2 score: 0.0000\n",
            "ROUGE-L score: 0.6222\n",
            "New best model saved with BLEU score: 0.5835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/50: 100%|██████████| 29/29 [00:01<00:00, 24.44it/s, loss=2.77]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/50, Loss: 2.7541\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 75/75 [00:00<00:00, 164.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-1 score: 0.5556\n",
            "Average ROUGE-2 score: 0.0000\n",
            "Average ROUGE-L score: 0.5556\n",
            "Yes/No question accuracy: 56.2% (27/48) - for analysis only\n",
            "BLEU score: 0.5168\n",
            "ROUGE-1 score: 0.5556\n",
            "ROUGE-2 score: 0.0000\n",
            "ROUGE-L score: 0.5556\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/50: 100%|██████████| 29/29 [00:01<00:00, 26.08it/s, loss=2.99]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/50, Loss: 2.7027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 75/75 [00:00<00:00, 160.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-1 score: 0.5689\n",
            "Average ROUGE-2 score: 0.0000\n",
            "Average ROUGE-L score: 0.5689\n",
            "Yes/No question accuracy: 60.4% (29/48) - for analysis only\n",
            "BLEU score: 0.5302\n",
            "ROUGE-1 score: 0.5689\n",
            "ROUGE-2 score: 0.0000\n",
            "ROUGE-L score: 0.5689\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/50: 100%|██████████| 29/29 [00:01<00:00, 26.03it/s, loss=2.68]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/50, Loss: 2.6264\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 75/75 [00:00<00:00, 163.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-1 score: 0.5422\n",
            "Average ROUGE-2 score: 0.0000\n",
            "Average ROUGE-L score: 0.5422\n",
            "Yes/No question accuracy: 52.1% (25/48) - for analysis only\n",
            "BLEU score: 0.5035\n",
            "ROUGE-1 score: 0.5422\n",
            "ROUGE-2 score: 0.0000\n",
            "ROUGE-L score: 0.5422\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/50: 100%|██████████| 29/29 [00:01<00:00, 25.98it/s, loss=2.85]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/50, Loss: 2.5849\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 75/75 [00:00<00:00, 168.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-1 score: 0.5689\n",
            "Average ROUGE-2 score: 0.0000\n",
            "Average ROUGE-L score: 0.5689\n",
            "Yes/No question accuracy: 60.4% (29/48) - for analysis only\n",
            "BLEU score: 0.5302\n",
            "ROUGE-1 score: 0.5689\n",
            "ROUGE-2 score: 0.0000\n",
            "ROUGE-L score: 0.5689\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/50: 100%|██████████| 29/29 [00:01<00:00, 26.12it/s, loss=2.33]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/50, Loss: 2.4963\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 75/75 [00:00<00:00, 165.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-1 score: 0.5156\n",
            "Average ROUGE-2 score: 0.0000\n",
            "Average ROUGE-L score: 0.5156\n",
            "Yes/No question accuracy: 54.2% (26/48) - for analysis only\n",
            "BLEU score: 0.4768\n",
            "ROUGE-1 score: 0.5156\n",
            "ROUGE-2 score: 0.0000\n",
            "ROUGE-L score: 0.5156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/50: 100%|██████████| 29/29 [00:01<00:00, 25.96it/s, loss=2.26]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/50, Loss: 2.4358\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 75/75 [00:00<00:00, 166.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-1 score: 0.5822\n",
            "Average ROUGE-2 score: 0.0000\n",
            "Average ROUGE-L score: 0.5822\n",
            "Yes/No question accuracy: 58.3% (28/48) - for analysis only\n",
            "BLEU score: 0.5435\n",
            "ROUGE-1 score: 0.5822\n",
            "ROUGE-2 score: 0.0000\n",
            "ROUGE-L score: 0.5822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/50: 100%|██████████| 29/29 [00:01<00:00, 24.95it/s, loss=2.71]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22/50, Loss: 2.3979\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 75/75 [00:00<00:00, 121.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-1 score: 0.5289\n",
            "Average ROUGE-2 score: 0.0000\n",
            "Average ROUGE-L score: 0.5289\n",
            "Yes/No question accuracy: 56.2% (27/48) - for analysis only\n",
            "BLEU score: 0.4902\n",
            "ROUGE-1 score: 0.5289\n",
            "ROUGE-2 score: 0.0000\n",
            "ROUGE-L score: 0.5289\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/50: 100%|██████████| 29/29 [00:01<00:00, 25.51it/s, loss=2.36]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23/50, Loss: 2.3567\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 75/75 [00:00<00:00, 113.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-1 score: 0.5956\n",
            "Average ROUGE-2 score: 0.0000\n",
            "Average ROUGE-L score: 0.5956\n",
            "Yes/No question accuracy: 66.7% (32/48) - for analysis only\n",
            "BLEU score: 0.5568\n",
            "ROUGE-1 score: 0.5956\n",
            "ROUGE-2 score: 0.0000\n",
            "ROUGE-L score: 0.5956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/50: 100%|██████████| 29/29 [00:01<00:00, 26.24it/s, loss=2.25]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24/50, Loss: 2.3009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 75/75 [00:00<00:00, 161.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-1 score: 0.6089\n",
            "Average ROUGE-2 score: 0.0000\n",
            "Average ROUGE-L score: 0.6089\n",
            "Yes/No question accuracy: 62.5% (30/48) - for analysis only\n",
            "BLEU score: 0.5702\n",
            "ROUGE-1 score: 0.6089\n",
            "ROUGE-2 score: 0.0000\n",
            "ROUGE-L score: 0.6089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/50: 100%|██████████| 29/29 [00:01<00:00, 25.95it/s, loss=2.17]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25/50, Loss: 2.2653\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 75/75 [00:00<00:00, 166.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-1 score: 0.5556\n",
            "Average ROUGE-2 score: 0.0000\n",
            "Average ROUGE-L score: 0.5556\n",
            "Yes/No question accuracy: 60.4% (29/48) - for analysis only\n",
            "BLEU score: 0.5272\n",
            "ROUGE-1 score: 0.5556\n",
            "ROUGE-2 score: 0.0000\n",
            "ROUGE-L score: 0.5556\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/50: 100%|██████████| 29/29 [00:01<00:00, 25.93it/s, loss=2.4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26/50, Loss: 2.2139\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 75/75 [00:00<00:00, 170.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-1 score: 0.5422\n",
            "Average ROUGE-2 score: 0.0000\n",
            "Average ROUGE-L score: 0.5422\n",
            "Yes/No question accuracy: 56.2% (27/48) - for analysis only\n",
            "BLEU score: 0.5035\n",
            "ROUGE-1 score: 0.5422\n",
            "ROUGE-2 score: 0.0000\n",
            "ROUGE-L score: 0.5422\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27/50: 100%|██████████| 29/29 [00:01<00:00, 26.13it/s, loss=2.11]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27/50, Loss: 2.1750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 75/75 [00:00<00:00, 163.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-1 score: 0.5956\n",
            "Average ROUGE-2 score: 0.0000\n",
            "Average ROUGE-L score: 0.5956\n",
            "Yes/No question accuracy: 64.6% (31/48) - for analysis only\n",
            "BLEU score: 0.5568\n",
            "ROUGE-1 score: 0.5956\n",
            "ROUGE-2 score: 0.0000\n",
            "ROUGE-L score: 0.5956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28/50: 100%|██████████| 29/29 [00:01<00:00, 26.09it/s, loss=2.42]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28/50, Loss: 2.1304\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 75/75 [00:00<00:00, 166.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-1 score: 0.5956\n",
            "Average ROUGE-2 score: 0.0000\n",
            "Average ROUGE-L score: 0.5956\n",
            "Yes/No question accuracy: 62.5% (30/48) - for analysis only\n",
            "BLEU score: 0.5568\n",
            "ROUGE-1 score: 0.5956\n",
            "ROUGE-2 score: 0.0000\n",
            "ROUGE-L score: 0.5956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29/50: 100%|██████████| 29/29 [00:01<00:00, 26.10it/s, loss=2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29/50, Loss: 2.1011\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 75/75 [00:00<00:00, 164.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-1 score: 0.5822\n",
            "Average ROUGE-2 score: 0.0000\n",
            "Average ROUGE-L score: 0.5822\n",
            "Yes/No question accuracy: 60.4% (29/48) - for analysis only\n",
            "BLEU score: 0.5435\n",
            "ROUGE-1 score: 0.5822\n",
            "ROUGE-2 score: 0.0000\n",
            "ROUGE-L score: 0.5822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30/50: 100%|██████████| 29/29 [00:01<00:00, 25.70it/s, loss=2.41]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30/50, Loss: 2.0864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 75/75 [00:00<00:00, 126.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-1 score: 0.5289\n",
            "Average ROUGE-2 score: 0.0000\n",
            "Average ROUGE-L score: 0.5289\n",
            "Yes/No question accuracy: 56.2% (27/48) - for analysis only\n",
            "BLEU score: 0.4902\n",
            "ROUGE-1 score: 0.5289\n",
            "ROUGE-2 score: 0.0000\n",
            "ROUGE-L score: 0.5289\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 31/50: 100%|██████████| 29/29 [00:01<00:00, 24.31it/s, loss=1.89]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31/50, Loss: 2.0291\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 75/75 [00:00<00:00, 109.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-1 score: 0.5289\n",
            "Average ROUGE-2 score: 0.0000\n",
            "Average ROUGE-L score: 0.5289\n",
            "Yes/No question accuracy: 54.2% (26/48) - for analysis only\n",
            "BLEU score: 0.4902\n",
            "ROUGE-1 score: 0.5289\n",
            "ROUGE-2 score: 0.0000\n",
            "ROUGE-L score: 0.5289\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 32/50: 100%|██████████| 29/29 [00:01<00:00, 25.68it/s, loss=2.59]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32/50, Loss: 2.0163\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 75/75 [00:00<00:00, 165.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-1 score: 0.5689\n",
            "Average ROUGE-2 score: 0.0000\n",
            "Average ROUGE-L score: 0.5689\n",
            "Yes/No question accuracy: 60.4% (29/48) - for analysis only\n",
            "BLEU score: 0.5349\n",
            "ROUGE-1 score: 0.5689\n",
            "ROUGE-2 score: 0.0000\n",
            "ROUGE-L score: 0.5689\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 33/50: 100%|██████████| 29/29 [00:01<00:00, 25.63it/s, loss=1.95]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33/50, Loss: 1.9487\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 75/75 [00:00<00:00, 166.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-1 score: 0.5822\n",
            "Average ROUGE-2 score: 0.0000\n",
            "Average ROUGE-L score: 0.5822\n",
            "Yes/No question accuracy: 58.3% (28/48) - for analysis only\n",
            "BLEU score: 0.5378\n",
            "ROUGE-1 score: 0.5822\n",
            "ROUGE-2 score: 0.0000\n",
            "ROUGE-L score: 0.5822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 34/50: 100%|██████████| 29/29 [00:01<00:00, 26.01it/s, loss=1.93]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34/50, Loss: 1.9449\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 75/75 [00:00<00:00, 159.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-1 score: 0.5422\n",
            "Average ROUGE-2 score: 0.0000\n",
            "Average ROUGE-L score: 0.5422\n",
            "Yes/No question accuracy: 54.2% (26/48) - for analysis only\n",
            "BLEU score: 0.5139\n",
            "ROUGE-1 score: 0.5422\n",
            "ROUGE-2 score: 0.0000\n",
            "ROUGE-L score: 0.5422\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 35/50: 100%|██████████| 29/29 [00:01<00:00, 26.01it/s, loss=1.82]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35/50, Loss: 1.9132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 75/75 [00:00<00:00, 161.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-1 score: 0.5556\n",
            "Average ROUGE-2 score: 0.0000\n",
            "Average ROUGE-L score: 0.5556\n",
            "Yes/No question accuracy: 58.3% (28/48) - for analysis only\n",
            "BLEU score: 0.5206\n",
            "ROUGE-1 score: 0.5556\n",
            "ROUGE-2 score: 0.0000\n",
            "ROUGE-L score: 0.5556\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 36/50: 100%|██████████| 29/29 [00:01<00:00, 25.89it/s, loss=1.75]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36/50, Loss: 1.8876\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 75/75 [00:00<00:00, 156.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-1 score: 0.5822\n",
            "Average ROUGE-2 score: 0.0000\n",
            "Average ROUGE-L score: 0.5822\n",
            "Yes/No question accuracy: 58.3% (28/48) - for analysis only\n",
            "BLEU score: 0.5378\n",
            "ROUGE-1 score: 0.5822\n",
            "ROUGE-2 score: 0.0000\n",
            "ROUGE-L score: 0.5822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 37/50: 100%|██████████| 29/29 [00:01<00:00, 25.76it/s, loss=1.74]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37/50, Loss: 1.8526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 75/75 [00:00<00:00, 159.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-1 score: 0.5822\n",
            "Average ROUGE-2 score: 0.0000\n",
            "Average ROUGE-L score: 0.5822\n",
            "Yes/No question accuracy: 62.5% (30/48) - for analysis only\n",
            "BLEU score: 0.5539\n",
            "ROUGE-1 score: 0.5822\n",
            "ROUGE-2 score: 0.0000\n",
            "ROUGE-L score: 0.5822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 38/50: 100%|██████████| 29/29 [00:01<00:00, 24.56it/s, loss=1.76]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38/50, Loss: 1.8529\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 75/75 [00:00<00:00, 123.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-1 score: 0.5822\n",
            "Average ROUGE-2 score: 0.0000\n",
            "Average ROUGE-L score: 0.5822\n",
            "Yes/No question accuracy: 64.6% (31/48) - for analysis only\n",
            "BLEU score: 0.5539\n",
            "ROUGE-1 score: 0.5822\n",
            "ROUGE-2 score: 0.0000\n",
            "ROUGE-L score: 0.5822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 39/50: 100%|██████████| 29/29 [00:01<00:00, 25.24it/s, loss=1.76]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39/50, Loss: 1.8225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 75/75 [00:00<00:00, 114.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-1 score: 0.5022\n",
            "Average ROUGE-2 score: 0.0000\n",
            "Average ROUGE-L score: 0.5022\n",
            "Yes/No question accuracy: 54.2% (26/48) - for analysis only\n",
            "BLEU score: 0.4739\n",
            "ROUGE-1 score: 0.5022\n",
            "ROUGE-2 score: 0.0000\n",
            "ROUGE-L score: 0.5022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 40/50: 100%|██████████| 29/29 [00:01<00:00, 25.37it/s, loss=1.65]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40/50, Loss: 1.8003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 75/75 [00:00<00:00, 163.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-1 score: 0.5689\n",
            "Average ROUGE-2 score: 0.0000\n",
            "Average ROUGE-L score: 0.5689\n",
            "Yes/No question accuracy: 60.4% (29/48) - for analysis only\n",
            "BLEU score: 0.5349\n",
            "ROUGE-1 score: 0.5689\n",
            "ROUGE-2 score: 0.0000\n",
            "ROUGE-L score: 0.5689\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 41/50: 100%|██████████| 29/29 [00:01<00:00, 25.98it/s, loss=1.79]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41/50, Loss: 1.8141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 75/75 [00:00<00:00, 158.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-1 score: 0.5822\n",
            "Average ROUGE-2 score: 0.0000\n",
            "Average ROUGE-L score: 0.5822\n",
            "Yes/No question accuracy: 60.4% (29/48) - for analysis only\n",
            "BLEU score: 0.5435\n",
            "ROUGE-1 score: 0.5822\n",
            "ROUGE-2 score: 0.0000\n",
            "ROUGE-L score: 0.5822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 42/50: 100%|██████████| 29/29 [00:01<00:00, 25.82it/s, loss=1.79]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42/50, Loss: 1.7722\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 75/75 [00:00<00:00, 164.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-1 score: 0.6089\n",
            "Average ROUGE-2 score: 0.0000\n",
            "Average ROUGE-L score: 0.6089\n",
            "Yes/No question accuracy: 62.5% (30/48) - for analysis only\n",
            "BLEU score: 0.5645\n",
            "ROUGE-1 score: 0.6089\n",
            "ROUGE-2 score: 0.0000\n",
            "ROUGE-L score: 0.6089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 43/50: 100%|██████████| 29/29 [00:01<00:00, 25.76it/s, loss=2.01]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43/50, Loss: 1.8020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 75/75 [00:00<00:00, 165.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-1 score: 0.5422\n",
            "Average ROUGE-2 score: 0.0000\n",
            "Average ROUGE-L score: 0.5422\n",
            "Yes/No question accuracy: 54.2% (26/48) - for analysis only\n",
            "BLEU score: 0.5082\n",
            "ROUGE-1 score: 0.5422\n",
            "ROUGE-2 score: 0.0000\n",
            "ROUGE-L score: 0.5422\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 44/50: 100%|██████████| 29/29 [00:01<00:00, 25.79it/s, loss=1.69]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44/50, Loss: 1.7548\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 75/75 [00:00<00:00, 167.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-1 score: 0.6356\n",
            "Average ROUGE-2 score: 0.0000\n",
            "Average ROUGE-L score: 0.6356\n",
            "Yes/No question accuracy: 64.6% (31/48) - for analysis only\n",
            "BLEU score: 0.5912\n",
            "ROUGE-1 score: 0.6356\n",
            "ROUGE-2 score: 0.0000\n",
            "ROUGE-L score: 0.6356\n",
            "New best model saved with BLEU score: 0.5912\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 45/50: 100%|██████████| 29/29 [00:01<00:00, 24.34it/s, loss=1.82]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45/50, Loss: 1.7337\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 75/75 [00:00<00:00, 158.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-1 score: 0.5422\n",
            "Average ROUGE-2 score: 0.0000\n",
            "Average ROUGE-L score: 0.5422\n",
            "Yes/No question accuracy: 54.2% (26/48) - for analysis only\n",
            "BLEU score: 0.5082\n",
            "ROUGE-1 score: 0.5422\n",
            "ROUGE-2 score: 0.0000\n",
            "ROUGE-L score: 0.5422\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 46/50: 100%|██████████| 29/29 [00:01<00:00, 25.76it/s, loss=1.65]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46/50, Loss: 1.7165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 75/75 [00:00<00:00, 168.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-1 score: 0.5689\n",
            "Average ROUGE-2 score: 0.0000\n",
            "Average ROUGE-L score: 0.5689\n",
            "Yes/No question accuracy: 62.5% (30/48) - for analysis only\n",
            "BLEU score: 0.5509\n",
            "ROUGE-1 score: 0.5689\n",
            "ROUGE-2 score: 0.0000\n",
            "ROUGE-L score: 0.5689\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 47/50: 100%|██████████| 29/29 [00:01<00:00, 25.60it/s, loss=1.75]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47/50, Loss: 1.7127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 75/75 [00:00<00:00, 153.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-1 score: 0.4889\n",
            "Average ROUGE-2 score: 0.0000\n",
            "Average ROUGE-L score: 0.4889\n",
            "Yes/No question accuracy: 47.9% (23/48) - for analysis only\n",
            "BLEU score: 0.4549\n",
            "ROUGE-1 score: 0.4889\n",
            "ROUGE-2 score: 0.0000\n",
            "ROUGE-L score: 0.4889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 48/50: 100%|██████████| 29/29 [00:01<00:00, 25.84it/s, loss=1.64]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48/50, Loss: 1.6984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 75/75 [00:00<00:00, 164.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-1 score: 0.6089\n",
            "Average ROUGE-2 score: 0.0000\n",
            "Average ROUGE-L score: 0.6089\n",
            "Yes/No question accuracy: 62.5% (30/48) - for analysis only\n",
            "BLEU score: 0.5645\n",
            "ROUGE-1 score: 0.6089\n",
            "ROUGE-2 score: 0.0000\n",
            "ROUGE-L score: 0.6089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 49/50: 100%|██████████| 29/29 [00:01<00:00, 25.71it/s, loss=1.71]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49/50, Loss: 1.6909\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 75/75 [00:00<00:00, 160.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-1 score: 0.5956\n",
            "Average ROUGE-2 score: 0.0000\n",
            "Average ROUGE-L score: 0.5956\n",
            "Yes/No question accuracy: 58.3% (28/48) - for analysis only\n",
            "BLEU score: 0.5615\n",
            "ROUGE-1 score: 0.5956\n",
            "ROUGE-2 score: 0.0000\n",
            "ROUGE-L score: 0.5956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 50/50: 100%|██████████| 29/29 [00:01<00:00, 25.68it/s, loss=1.64]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50/50, Loss: 1.6869\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 75/75 [00:00<00:00, 158.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE-1 score: 0.5822\n",
            "Average ROUGE-2 score: 0.0000\n",
            "Average ROUGE-L score: 0.5822\n",
            "Yes/No question accuracy: 62.5% (30/48) - for analysis only\n",
            "BLEU score: 0.5482\n",
            "ROUGE-1 score: 0.5822\n",
            "ROUGE-2 score: 0.0000\n",
            "ROUGE-L score: 0.5822\n",
            "Restored best model with BLEU score: 0.5912\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "not enough values to unpack (expected 5, got 2)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-01b328c38e6d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    412\u001b[0m )\n\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m fusion_model, fusion_best_bleu, fusion_best_rouge1, fusion_best_rouge2, fusion_best_rougeL = train_vqa_model(\n\u001b[0m\u001b[1;32m    415\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfusion_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 5, got 2)"
          ]
        }
      ],
      "source": [
        "\n",
        "class ImprovedCrossAttentionFusionGenerator(nn.Module):\n",
        "    def __init__(self, vocab_size, image_dim=1024, text_dim=256, fusion_dim=512,\n",
        "                 dec_dim=512, num_heads=8, dropout=0.3):  # Keep increased dropout\n",
        "        super().__init__()\n",
        "        # Project image and text features\n",
        "        self.image_proj = nn.Linear(image_dim, fusion_dim)\n",
        "        self.text_proj = nn.Linear(text_dim, fusion_dim)\n",
        "\n",
        "        # Token expanders (transform features into sequences)\n",
        "        self.img_to_tokens = nn.Linear(fusion_dim, fusion_dim * 4)  # Expand to 4 tokens\n",
        "        self.txt_to_tokens = nn.Linear(fusion_dim, fusion_dim * 4)  # Expand to 4 tokens\n",
        "\n",
        "        # Co-attention between modalities\n",
        "        self.img_txt_attn = nn.MultiheadAttention(\n",
        "            embed_dim=fusion_dim,\n",
        "            num_heads=num_heads//2,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.txt_img_attn = nn.MultiheadAttention(\n",
        "            embed_dim=fusion_dim,\n",
        "            num_heads=num_heads//2,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        # Fusion layer normalization\n",
        "        self.fusion_ln = nn.LayerNorm(fusion_dim)\n",
        "\n",
        "        # Token embedding for decoder\n",
        "        self.embedding = nn.Embedding(vocab_size, dec_dim, padding_idx=0)\n",
        "\n",
        "        # Cross-attention layer\n",
        "        self.cross_attn = nn.MultiheadAttention(\n",
        "            embed_dim=dec_dim,\n",
        "            num_heads=num_heads,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        # Decoder LSTM\n",
        "        self.decoder_lstm = nn.LSTM(\n",
        "            input_size=dec_dim,\n",
        "            hidden_size=dec_dim,\n",
        "            num_layers=2,\n",
        "            batch_first=True,\n",
        "            dropout=dropout\n",
        "        )\n",
        "\n",
        "        # Add layer norm and more dropout\n",
        "        self.pre_output_ln = nn.LayerNorm(dec_dim)\n",
        "        self.pre_output_dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # Final projection\n",
        "        self.output_head = nn.Linear(dec_dim, vocab_size)\n",
        "\n",
        "    def forward(self, img_feat, txt_feat, decoder_input_ids, temperature=0.1):\n",
        "        B = img_feat.size(0)  # Batch size\n",
        "\n",
        "        # Project image and text to same fusion space\n",
        "        img_proj = self.image_proj(img_feat)    # [B, fusion_dim]\n",
        "        txt_proj = self.text_proj(txt_feat)     # [B, fusion_dim]\n",
        "\n",
        "        # Expand to token sequences\n",
        "        img_tokens = self.img_to_tokens(img_proj).reshape(B, 4, -1)  # [B, 4, fusion_dim]\n",
        "        txt_tokens = self.txt_to_tokens(txt_proj).reshape(B, 4, -1)  # [B, 4, fusion_dim]\n",
        "\n",
        "        # Co-attention between modalities\n",
        "        img_attn_to_txt, _ = self.img_txt_attn(img_tokens, txt_tokens, txt_tokens)\n",
        "        txt_attn_to_img, _ = self.txt_img_attn(txt_tokens, img_tokens, img_tokens)\n",
        "\n",
        "        # Combine and normalize\n",
        "        fusion_memory = torch.cat([img_attn_to_txt, txt_attn_to_img], dim=1)  # [B, 8, fusion_dim]\n",
        "        fusion_memory = self.fusion_ln(fusion_memory)\n",
        "\n",
        "        # Embed decoder input tokens\n",
        "        dec_emb = self.embedding(decoder_input_ids)  # [B, T, dec_dim]\n",
        "\n",
        "        # Cross-attention: decoder attends to fused image+text features\n",
        "        attn_output, _ = self.cross_attn(\n",
        "            query=dec_emb,\n",
        "            key=fusion_memory,\n",
        "            value=fusion_memory\n",
        "        )  # [B, T, dec_dim]\n",
        "\n",
        "        # Feed through LSTM\n",
        "        lstm_output, (_, _) = self.decoder_lstm(attn_output)  # [B, T, dec_dim]\n",
        "\n",
        "        # Apply layer norm and dropout before final output\n",
        "        lstm_output = self.pre_output_ln(lstm_output)\n",
        "        lstm_output = self.pre_output_dropout(lstm_output)\n",
        "\n",
        "        # Project to vocabulary logits\n",
        "        logits = self.output_head(lstm_output)   # [B, T, vocab_size]\n",
        "\n",
        "        # Apply temperature for generation diversity\n",
        "        if temperature != 1.0:\n",
        "            logits = logits / temperature\n",
        "\n",
        "        return logits\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "\n",
        "def evaluate_model(model, test_loader, tokenizer, device, temperature=0.9):  # Lower temperature for generation\n",
        "    \"\"\"\n",
        "    Evaluate model on test set and calculate BLEU score\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    all_bleu_scores = []\n",
        "\n",
        "    # Store yes/no accuracy separately for analysis\n",
        "    binary_correct = 0\n",
        "    binary_total = 0\n",
        "\n",
        "    # Use smoothing for BLEU calculation\n",
        "    smoothie = SmoothingFunction().method4  # Changed to method4 for consistency\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
        "            # Unpack batch\n",
        "            img_feats, txt_feats, q_ids, q_mask, decoder_inputs, labels = [b.to(device) for b in batch]\n",
        "\n",
        "            # Get question text for analysis\n",
        "            question = tokenizer.decode(q_ids[0].cpu().tolist(), skip_special_tokens=True).lower()\n",
        "            is_binary = any(question.startswith(prefix) for prefix in [\"is \", \"are \", \"can \", \"do \", \"does \"])\n",
        "\n",
        "            # Reference answer (ground truth)\n",
        "            reference_ids = labels[0].cpu().tolist()\n",
        "            reference_ids = [id for id in reference_ids if id != 0]  # Remove padding\n",
        "            reference = tokenizer.decode(reference_ids, skip_special_tokens=True).lower()\n",
        "\n",
        "            # For evaluation, we generate one token at a time\n",
        "            # Start with BOS token (101)\n",
        "            current_input = torch.tensor([[101]], device=device)\n",
        "            generated_ids = [101]\n",
        "\n",
        "            # Generate tokens auto-regressively\n",
        "            max_len = 8  # Maximum answer length\n",
        "            for _ in range(max_len - 1):\n",
        "                # Forward pass (with temperature)\n",
        "                logits = model(img_feats, txt_feats, current_input, temperature)\n",
        "\n",
        "                # Get the most likely next token\n",
        "                next_token_id = logits[0, -1].argmax().item()\n",
        "\n",
        "                # Stop if we hit the EOS token (102)\n",
        "                if next_token_id == 102:\n",
        "                    break\n",
        "\n",
        "                # Add token to the sequence\n",
        "                generated_ids.append(next_token_id)\n",
        "\n",
        "                # Update input for next iteration\n",
        "                current_input = torch.cat([\n",
        "                    current_input,\n",
        "                    torch.tensor([[next_token_id]], device=device)\n",
        "                ], dim=1)\n",
        "\n",
        "            # Get the predicted answer\n",
        "            prediction = tokenizer.decode(generated_ids[1:], skip_special_tokens=True).lower()\n",
        "\n",
        "            # Track binary question accuracy separately\n",
        "            if is_binary:\n",
        "                binary_total += 1\n",
        "                if (prediction == \"yes\" and reference == \"yes\") or (prediction == \"no\" and reference == \"no\"):\n",
        "                    binary_correct += 1\n",
        "\n",
        "            # Convert IDs to tokens for BLEU calculation\n",
        "            reference_tokens = tokenizer.convert_ids_to_tokens(reference_ids)\n",
        "            generated_tokens = tokenizer.convert_ids_to_tokens(generated_ids[1:])  # Skip BOS token\n",
        "\n",
        "            # Remove special tokens\n",
        "            reference_tokens = [token for token in reference_tokens if token not in ['[CLS]', '[SEP]', '[PAD]']]\n",
        "            generated_tokens = [token for token in generated_tokens if token not in ['[CLS]', '[SEP]', '[PAD]']]\n",
        "\n",
        "            # Calculate BLEU score (with smoothing for short sequences)\n",
        "            # If either sequence is empty, assign a score of 0\n",
        "            if len(reference_tokens) == 0 or len(generated_tokens) == 0:\n",
        "                bleu = 0\n",
        "            else:\n",
        "                bleu = sentence_bleu([reference_tokens], generated_tokens,\n",
        "                                     smoothing_function=smoothie)\n",
        "\n",
        "            all_bleu_scores.append(bleu)\n",
        "\n",
        "    # Calculate average BLEU score\n",
        "    avg_bleu = np.mean(all_bleu_scores)\n",
        "\n",
        "    # Print binary accuracy if applicable\n",
        "    if binary_total > 0:\n",
        "        binary_acc = binary_correct / binary_total * 100\n",
        "        print(f\"Yes/No question accuracy: {binary_acc:.1f}% ({binary_correct}/{binary_total}) - for analysis only\")\n",
        "\n",
        "    return avg_bleu\n",
        "# Simplify the train function to use the unified model approach\n",
        "def train_vqa_model(model, train_loader, test_loader, tokenizer,\n",
        "                    num_epochs=60, lr=5e-4, device='cuda'):\n",
        "    \"\"\"\n",
        "    Train the VQA model and evaluate on test set\n",
        "    Returns the model with best BLEU score and the score itself\n",
        "    \"\"\"\n",
        "    # Move model to device\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Define loss function (with label smoothing)\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=0, label_smoothing=0.1)  # Add label smoothing\n",
        "\n",
        "    # Define optimizer\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    # Learning rate scheduler\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='min', factor=0.5, patience=3, verbose=True\n",
        "    )\n",
        "\n",
        "    # Training loop\n",
        "    best_bleu = 0.0\n",
        "    best_model_state = None\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        # Training loop\n",
        "        train_loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "        for batch in train_loop:\n",
        "            # Unpack batch\n",
        "            img_feats, txt_feats, _, _, decoder_inputs, labels = [b.to(device) for b in batch]\n",
        "\n",
        "            # Forward pass\n",
        "            logits = model(img_feats, txt_feats, decoder_inputs)\n",
        "\n",
        "            # Calculate loss\n",
        "            B, T, V = logits.shape\n",
        "            loss = criterion(logits.view(-1, V), labels.view(-1))\n",
        "\n",
        "            # Backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "\n",
        "            # Gradient clipping to prevent exploding gradients\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "            # Update weights\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update statistics\n",
        "            total_loss += loss.item()\n",
        "            train_loop.set_postfix(loss=loss.item())\n",
        "\n",
        "        # Calculate average loss\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
        "\n",
        "        # Update learning rate based on loss\n",
        "        scheduler.step(avg_loss)\n",
        "\n",
        "        # Evaluate on test set\n",
        "        bleu_score, rouge1_score, rouge2_score, rougeL_score = evaluate_model(model, test_loader, tokenizer, device)\n",
        "\n",
        "        # Print all scores\n",
        "        print(f\"BLEU score: {bleu_score:.4f}\")\n",
        "        print(f\"ROUGE-1 score: {rouge1_score:.4f}\")\n",
        "        print(f\"ROUGE-2 score: {rouge2_score:.4f}\")\n",
        "        print(f\"ROUGE-L score: {rougeL_score:.4f}\")\n",
        "\n",
        "        # Save best model\n",
        "        if bleu_score > best_bleu:\n",
        "            best_bleu = bleu_score\n",
        "            # Save model state to file\n",
        "            torch.save(model.state_dict(), \"best_vqa_model.pth\")\n",
        "            # Also keep a copy of the best model state in memory\n",
        "            best_model_state = model.state_dict().copy()\n",
        "            print(f\"New best model saved with BLEU score: {best_bleu:.4f}\")\n",
        "\n",
        "    # Load the best model state before returning\n",
        "    if best_model_state is not None:\n",
        "        model.load_state_dict(best_model_state)\n",
        "        print(f\"Restored best model with BLEU score: {best_bleu:.4f}\")\n",
        "\n",
        "    # Return best model and its BLEU score\n",
        "    return model, best_bleu\n",
        "\n",
        "# Update the evaluate_model function to use temperature scaling\n",
        "def evaluate_model(model, test_loader, tokenizer, device, temperature=0.5):\n",
        "    \"\"\"\n",
        "    Evaluate model on test set and calculate BLEU and ROUGE scores\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    all_bleu_scores = []\n",
        "    all_rouge1_scores = []\n",
        "    all_rouge2_scores = []\n",
        "    all_rougeL_scores = []\n",
        "\n",
        "    # Store yes/no accuracy separately for analysis\n",
        "    binary_correct = 0\n",
        "    binary_total = 0\n",
        "\n",
        "    # Use smoothing for BLEU calculation\n",
        "    smoothie = SmoothingFunction().method4\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
        "            # Unpack batch\n",
        "            img_feats, txt_feats, q_ids, q_mask, _, labels = [b.to(device) for b in batch]\n",
        "\n",
        "            # Get question text for analysis\n",
        "            question = tokenizer.decode(q_ids[0].cpu().tolist(), skip_special_tokens=True).lower()\n",
        "            is_binary = any(question.startswith(prefix) for prefix in [\"is \", \"are \", \"can \", \"do \", \"does \"])\n",
        "\n",
        "            # Reference answer (ground truth)\n",
        "            reference_ids = labels[0].cpu().tolist()\n",
        "            reference_ids = [id for id in reference_ids if id != 0]  # Remove padding\n",
        "            reference = tokenizer.decode(reference_ids, skip_special_tokens=True).lower()\n",
        "\n",
        "            # For evaluation, we generate one token at a time\n",
        "            # Start with BOS token (101)\n",
        "            current_input = torch.tensor([[101]], device=device)\n",
        "            generated_ids = [101]\n",
        "\n",
        "            # Generate tokens auto-regressively\n",
        "            max_len = 8  # Maximum answer length\n",
        "            for _ in range(max_len - 1):\n",
        "                # Forward pass with temperature scaling\n",
        "                logits = model(img_feats, txt_feats, current_input)\n",
        "\n",
        "                # Apply temperature scaling\n",
        "                logits = logits / temperature\n",
        "\n",
        "                # Get the most likely next token\n",
        "                next_token_id = logits[0, -1].argmax().item()\n",
        "\n",
        "                # Stop if we hit the EOS token (102)\n",
        "                if next_token_id == 102:\n",
        "                    break\n",
        "\n",
        "                # Add token to the sequence\n",
        "                generated_ids.append(next_token_id)\n",
        "\n",
        "                # Update input for next iteration\n",
        "                current_input = torch.cat([\n",
        "                    current_input,\n",
        "                    torch.tensor([[next_token_id]], device=device)\n",
        "                ], dim=1)\n",
        "\n",
        "            # Get the predicted answer\n",
        "            prediction = tokenizer.decode(generated_ids[1:], skip_special_tokens=True).lower()\n",
        "\n",
        "            # Track binary question accuracy separately\n",
        "            if is_binary:\n",
        "                binary_total += 1\n",
        "                if (prediction == \"yes\" and reference == \"yes\") or (prediction == \"no\" and reference == \"no\"):\n",
        "                    binary_correct += 1\n",
        "\n",
        "            # Convert IDs to tokens for BLEU calculation\n",
        "            reference_tokens = tokenizer.convert_ids_to_tokens(reference_ids)\n",
        "            generated_tokens = tokenizer.convert_ids_to_tokens(generated_ids[1:])  # Skip BOS token\n",
        "\n",
        "            # Remove special tokens\n",
        "            reference_tokens = [token for token in reference_tokens if token not in ['[CLS]', '[SEP]', '[PAD]']]\n",
        "            generated_tokens = [token for token in generated_tokens if token not in ['[CLS]', '[SEP]', '[PAD]']]\n",
        "\n",
        "            # Calculate BLEU score (with smoothing for short sequences)\n",
        "            if len(reference_tokens) == 0 or len(generated_tokens) == 0:\n",
        "                bleu = 0\n",
        "            else:\n",
        "                bleu = sentence_bleu([reference_tokens], generated_tokens,\n",
        "                                    smoothing_function=smoothie)\n",
        "\n",
        "            all_bleu_scores.append(bleu)\n",
        "\n",
        "            # Calculate ROUGE scores for this example\n",
        "            rouge_scores = scorer.score(reference, prediction)\n",
        "            all_rouge1_scores.append(rouge_scores['rouge1'].fmeasure)\n",
        "            all_rouge2_scores.append(rouge_scores['rouge2'].fmeasure)\n",
        "            all_rougeL_scores.append(rouge_scores['rougeL'].fmeasure)\n",
        "\n",
        "    # Calculate average scores\n",
        "    avg_bleu = np.mean(all_bleu_scores)\n",
        "    avg_rouge1 = np.mean(all_rouge1_scores)\n",
        "    avg_rouge2 = np.mean(all_rouge2_scores)\n",
        "    avg_rougeL = np.mean(all_rougeL_scores)\n",
        "\n",
        "    # Print the average ROUGE scores\n",
        "    print(f\"Average ROUGE-1 score: {avg_rouge1:.4f}\")\n",
        "    print(f\"Average ROUGE-2 score: {avg_rouge2:.4f}\")\n",
        "    print(f\"Average ROUGE-L score: {avg_rougeL:.4f}\")\n",
        "\n",
        "    # Print binary accuracy if applicable\n",
        "    if binary_total > 0:\n",
        "        binary_acc = binary_correct / binary_total * 100\n",
        "        print(f\"Yes/No question accuracy: {binary_acc:.1f}% ({binary_correct}/{binary_total}) - for analysis only\")\n",
        "\n",
        "    return avg_bleu, avg_rouge1, avg_rouge2, avg_rougeL\n",
        "\n",
        "# Initialize your model (assuming it's already defined)\n",
        "fusion_generator = ImprovedCrossAttentionFusionGenerator(\n",
        "    vocab_size=tokenizer.vocab_size,\n",
        "    image_dim=1024,\n",
        "    text_dim=256,\n",
        "    fusion_dim=512,\n",
        "    dec_dim=512,\n",
        "    num_heads=8,\n",
        "    dropout=0.3\n",
        ")\n",
        "\n",
        "fusion_model, fusion_best_bleu, fusion_best_rouge1, fusion_best_rouge2, fusion_best_rougeL = train_vqa_model(\n",
        "    model=fusion_generator,\n",
        "    train_loader=train_loader,\n",
        "    test_loader=test_loader,\n",
        "    tokenizer=tokenizer,\n",
        "    num_epochs=50,\n",
        "    lr=1e-4,  # Lower learning rate\n",
        "    device=device\n",
        ")\n",
        "\n",
        "# Final evaluation on test set\n",
        "print(\"Running final evaluation on best model...\")\n",
        "fusion_model.eval()  # Ensure model is in evaluation mode\n",
        "\n",
        "# Add debugging to see actual predictions\n",
        "def debug_predictions(model, test_loader, tokenizer, device, num_samples=5):\n",
        "    \"\"\"Show predictions for a few test samples to help debug BLEU score issues\"\"\"\n",
        "    model.eval()\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            if count >= num_samples:\n",
        "                break\n",
        "\n",
        "            img_feats, txt_feats, q_ids, q_mask, decoder_inputs, labels = [b.to(device) for b in batch]\n",
        "\n",
        "            # Get question text\n",
        "            question = tokenizer.decode(q_ids[0].cpu().tolist(), skip_special_tokens=True)\n",
        "\n",
        "            # Get ground truth answer\n",
        "            reference_ids = labels[0].cpu().tolist()\n",
        "            reference_ids = [id for id in reference_ids if id != 0]  # Remove padding\n",
        "            reference = tokenizer.decode(reference_ids, skip_special_tokens=True)\n",
        "\n",
        "            # Generate prediction\n",
        "            current_input = torch.tensor([[101]], device=device)  # Start with BOS token\n",
        "            generated_ids = [101]\n",
        "\n",
        "            # Generate tokens auto-regressively\n",
        "            max_len = 8\n",
        "            for _ in range(max_len - 1):\n",
        "                logits = model(img_feats, txt_feats, current_input)\n",
        "                next_token_id = logits[0, -1].argmax().item()\n",
        "\n",
        "                if next_token_id == 102:  # EOS token\n",
        "                    break\n",
        "\n",
        "                generated_ids.append(next_token_id)\n",
        "                current_input = torch.cat([\n",
        "                    current_input,\n",
        "                    torch.tensor([[next_token_id]], device=device)\n",
        "                ], dim=1)\n",
        "\n",
        "            # Decode prediction\n",
        "            prediction = tokenizer.decode(generated_ids[1:], skip_special_tokens=True)\n",
        "\n",
        "            # Convert to tokens for BLEU calculation\n",
        "            reference_tokens = tokenizer.convert_ids_to_tokens(reference_ids)\n",
        "            generated_tokens = tokenizer.convert_ids_to_tokens(generated_ids[1:])\n",
        "\n",
        "            # Remove special tokens\n",
        "            reference_tokens = [token for token in reference_tokens if token not in ['[CLS]', '[SEP]', '[PAD]']]\n",
        "            generated_tokens = [token for token in generated_tokens if token not in ['[CLS]', '[SEP]', '[PAD]']]\n",
        "\n",
        "            # Print debug info\n",
        "            #print(f\"\\nSample {count+1}:\")\n",
        "            #print(f\"Question: {question}\")\n",
        "            #print(f\"Reference: '{reference}' (tokens: {reference_tokens})\")\n",
        "            #print(f\"Prediction: '{prediction}' (tokens: {generated_tokens})\")\n",
        "\n",
        "            # Calculate individual BLEU score\n",
        "            smoothie = SmoothingFunction().method4\n",
        "            if len(reference_tokens) == 0 or len(generated_tokens) == 0:\n",
        "                bleu = 0\n",
        "                reason = \"Empty tokens\"\n",
        "            else:\n",
        "                bleu = sentence_bleu([reference_tokens], generated_tokens, smoothing_function=smoothie)\n",
        "                reason = \"Valid tokens\"\n",
        "\n",
        "            print(f\"Individual BLEU: {bleu:.4f} ({reason})\")\n",
        "            count += 1\n",
        "\n",
        "# Run debugging\n",
        "debug_predictions(fusion_model, test_loader, tokenizer, device)\n",
        "\n",
        "# Then run the final evaluation\n",
        "final_bleu_score = evaluate_model(fusion_model, test_loader, tokenizer, device)\n",
        "print(f\"Final BLEU score on test set: {final_bleu_score:.4f}\")\n",
        "\n",
        "# Optional: Save the final model\n",
        "torch.save(fusion_model.state_dict(), \"final_vqa_model.pth\")\n",
        "print(\"Final model saved as final_vqa_model.pth\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-13QoIeA_M-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "X4UuaZZP_FM0"
      }
    }
  ]
}